{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a794a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db9073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeds for repoducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6506194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "          df = pd.read_csv(\"ML-Dataset.csv\")\n",
    "except FileNotFoundError:\n",
    "          print(\"Error: 'ML-Dataset.csv' not found. Please ensure the file is in the correct path.\")\n",
    "          exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "448ba600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "      <th>CountryName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>WarehouseAddress</th>\n",
       "      <th>WarehouseName</th>\n",
       "      <th>EmployeeName</th>\n",
       "      <th>EmployeeEmail</th>\n",
       "      <th>EmployeePhone</th>\n",
       "      <th>...</th>\n",
       "      <th>CustomerName</th>\n",
       "      <th>CustomerAddress</th>\n",
       "      <th>CustomerCreditLimit</th>\n",
       "      <th>CustomerEmail</th>\n",
       "      <th>CustomerPhone</th>\n",
       "      <th>Status</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>OrderItemQuantity</th>\n",
       "      <th>PerUnitPrice</th>\n",
       "      <th>TotalItemQuantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>26192</td>\n",
       "      <td>2014 Jabberwocky Rd</td>\n",
       "      <td>Southlake Texas</td>\n",
       "      <td>Summer Payne</td>\n",
       "      <td>summer.payne@example.com</td>\n",
       "      <td>5151238181</td>\n",
       "      <td>...</td>\n",
       "      <td>Flor Stone</td>\n",
       "      <td>2904 S Salina St</td>\n",
       "      <td>5000</td>\n",
       "      <td>flor.stone@raytheon.com</td>\n",
       "      <td>13171234104</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>17-Nov-16</td>\n",
       "      <td>132</td>\n",
       "      <td>469.99</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>26192</td>\n",
       "      <td>2014 Jabberwocky Rd</td>\n",
       "      <td>Southlake Texas</td>\n",
       "      <td>Rose Stephens</td>\n",
       "      <td>rose.stephens@example.com</td>\n",
       "      <td>5151238080</td>\n",
       "      <td>...</td>\n",
       "      <td>Lavera Emerson</td>\n",
       "      <td>5344 Haverford Ave, Philadelphia</td>\n",
       "      <td>5000</td>\n",
       "      <td>lavera.emerson@plainsallamerican.com</td>\n",
       "      <td>13171234111</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>20-Feb-17</td>\n",
       "      <td>124</td>\n",
       "      <td>519.99</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>26192</td>\n",
       "      <td>2014 Jabberwocky Rd</td>\n",
       "      <td>Southlake Texas</td>\n",
       "      <td>Annabelle Dunn</td>\n",
       "      <td>annabelle.dunn@example.com</td>\n",
       "      <td>5151234444</td>\n",
       "      <td>...</td>\n",
       "      <td>Fern Head</td>\n",
       "      <td>1795 Wu Meng, Muang Chonburi</td>\n",
       "      <td>1200</td>\n",
       "      <td>fern.head@usfoods.com</td>\n",
       "      <td>18121234115</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>03-Jan-17</td>\n",
       "      <td>92</td>\n",
       "      <td>800.74</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>26192</td>\n",
       "      <td>2014 Jabberwocky Rd</td>\n",
       "      <td>Southlake Texas</td>\n",
       "      <td>Tommy Bailey</td>\n",
       "      <td>tommy.bailey@example.com</td>\n",
       "      <td>5151234567</td>\n",
       "      <td>...</td>\n",
       "      <td>Shyla Ortiz</td>\n",
       "      <td>Walpurgisstr 69, Munich</td>\n",
       "      <td>2400</td>\n",
       "      <td>shyla.ortiz@abbvie.com</td>\n",
       "      <td>13171234126</td>\n",
       "      <td>Pending</td>\n",
       "      <td>15-Oct-17</td>\n",
       "      <td>128</td>\n",
       "      <td>849.99</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>26192</td>\n",
       "      <td>2014 Jabberwocky Rd</td>\n",
       "      <td>Southlake Texas</td>\n",
       "      <td>Blake Cooper</td>\n",
       "      <td>blake.cooper@example.com</td>\n",
       "      <td>5151234569</td>\n",
       "      <td>...</td>\n",
       "      <td>Jeni Levy</td>\n",
       "      <td>Via Frenzy 6903, Roma</td>\n",
       "      <td>1200</td>\n",
       "      <td>jeni.levy@centene.com</td>\n",
       "      <td>18121214129</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>09-Apr-17</td>\n",
       "      <td>106</td>\n",
       "      <td>109.99</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>490231</td>\n",
       "      <td>1298 Vileparle (E)</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Veera Abdellah</td>\n",
       "      <td>VeeraAbdellah@gmail.com</td>\n",
       "      <td>8788092231</td>\n",
       "      <td>...</td>\n",
       "      <td>Vega Vincent</td>\n",
       "      <td>4284 Dorigo Ln</td>\n",
       "      <td>4900</td>\n",
       "      <td>VegaVincent@gmail.com</td>\n",
       "      <td>787879874</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>27-Sep-17</td>\n",
       "      <td>32</td>\n",
       "      <td>725.99</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>490231</td>\n",
       "      <td>1298 Vileparle (E)</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Vega Vincent</td>\n",
       "      <td>VegaVincent@gmail.com</td>\n",
       "      <td>6700989921</td>\n",
       "      <td>...</td>\n",
       "      <td>Villanueva Noah</td>\n",
       "      <td>6794 Lake Dr E</td>\n",
       "      <td>5000</td>\n",
       "      <td>VillanuevaNoah@gmail.com</td>\n",
       "      <td>785811219</td>\n",
       "      <td>Pending</td>\n",
       "      <td>16-Aug-16</td>\n",
       "      <td>66</td>\n",
       "      <td>798.26</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>490231</td>\n",
       "      <td>1298 Vileparle (E)</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Villanueva Noah</td>\n",
       "      <td>VillanuevaNoah@gmail.com</td>\n",
       "      <td>7890991231</td>\n",
       "      <td>...</td>\n",
       "      <td>Voldemort Lord</td>\n",
       "      <td>31 Douglas Blvd #950</td>\n",
       "      <td>4000</td>\n",
       "      <td>VoldemortLord@gmail.com</td>\n",
       "      <td>789243757</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>27-May-16</td>\n",
       "      <td>82</td>\n",
       "      <td>849.99</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>490231</td>\n",
       "      <td>1298 Vileparle (E)</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Zima Colleen</td>\n",
       "      <td>ZimaColleen@gmail.com</td>\n",
       "      <td>8690991436</td>\n",
       "      <td>...</td>\n",
       "      <td>Lucy Cechtelar</td>\n",
       "      <td>44 W 4th St</td>\n",
       "      <td>3000</td>\n",
       "      <td>LucyCechtelar@gmail.com</td>\n",
       "      <td>964940981</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>27-May-17</td>\n",
       "      <td>157</td>\n",
       "      <td>821.99</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>490231</td>\n",
       "      <td>1298 Vileparle (E)</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Volk Colleen</td>\n",
       "      <td>VolkCollen@gmail.com</td>\n",
       "      <td>9426826971</td>\n",
       "      <td>...</td>\n",
       "      <td>John Snow</td>\n",
       "      <td>11279 Loytan St</td>\n",
       "      <td>2000</td>\n",
       "      <td>JohnSnow@gmail.com</td>\n",
       "      <td>567897474</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>27-May-17</td>\n",
       "      <td>32</td>\n",
       "      <td>579.59</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegionName               CountryName        State       City  \\\n",
       "0    South America  United States of America        Texas  Southlake   \n",
       "1    South America  United States of America        Texas  Southlake   \n",
       "2    South America  United States of America        Texas  Southlake   \n",
       "3    South America  United States of America        Texas  Southlake   \n",
       "4    South America  United States of America        Texas  Southlake   \n",
       "..             ...                       ...          ...        ...   \n",
       "395           Asia                     India  Maharashtra     Bombay   \n",
       "396           Asia                     India  Maharashtra     Bombay   \n",
       "397           Asia                     India  Maharashtra     Bombay   \n",
       "398           Asia                     India  Maharashtra     Bombay   \n",
       "399           Asia                     India  Maharashtra     Bombay   \n",
       "\n",
       "    PostalCode     WarehouseAddress    WarehouseName     EmployeeName  \\\n",
       "0        26192  2014 Jabberwocky Rd  Southlake Texas     Summer Payne   \n",
       "1        26192  2014 Jabberwocky Rd  Southlake Texas    Rose Stephens   \n",
       "2        26192  2014 Jabberwocky Rd  Southlake Texas   Annabelle Dunn   \n",
       "3        26192  2014 Jabberwocky Rd  Southlake Texas     Tommy Bailey   \n",
       "4        26192  2014 Jabberwocky Rd  Southlake Texas     Blake Cooper   \n",
       "..         ...                  ...              ...              ...   \n",
       "395     490231   1298 Vileparle (E)           Bombay   Veera Abdellah   \n",
       "396     490231   1298 Vileparle (E)           Bombay     Vega Vincent   \n",
       "397     490231   1298 Vileparle (E)           Bombay  Villanueva Noah   \n",
       "398     490231   1298 Vileparle (E)           Bombay     Zima Colleen   \n",
       "399     490231   1298 Vileparle (E)           Bombay     Volk Colleen   \n",
       "\n",
       "                  EmployeeEmail  EmployeePhone  ...     CustomerName  \\\n",
       "0      summer.payne@example.com     5151238181  ...       Flor Stone   \n",
       "1     rose.stephens@example.com     5151238080  ...   Lavera Emerson   \n",
       "2    annabelle.dunn@example.com     5151234444  ...        Fern Head   \n",
       "3      tommy.bailey@example.com     5151234567  ...      Shyla Ortiz   \n",
       "4      blake.cooper@example.com     5151234569  ...        Jeni Levy   \n",
       "..                          ...            ...  ...              ...   \n",
       "395     VeeraAbdellah@gmail.com     8788092231  ...     Vega Vincent   \n",
       "396       VegaVincent@gmail.com     6700989921  ...  Villanueva Noah   \n",
       "397    VillanuevaNoah@gmail.com     7890991231  ...   Voldemort Lord   \n",
       "398       ZimaColleen@gmail.com     8690991436  ...   Lucy Cechtelar   \n",
       "399        VolkCollen@gmail.com     9426826971  ...        John Snow   \n",
       "\n",
       "                      CustomerAddress CustomerCreditLimit  \\\n",
       "0                    2904 S Salina St                5000   \n",
       "1    5344 Haverford Ave, Philadelphia                5000   \n",
       "2        1795 Wu Meng, Muang Chonburi                1200   \n",
       "3             Walpurgisstr 69, Munich                2400   \n",
       "4               Via Frenzy 6903, Roma                1200   \n",
       "..                                ...                 ...   \n",
       "395                    4284 Dorigo Ln                4900   \n",
       "396                    6794 Lake Dr E                5000   \n",
       "397              31 Douglas Blvd #950                4000   \n",
       "398                       44 W 4th St                3000   \n",
       "399                   11279 Loytan St                2000   \n",
       "\n",
       "                            CustomerEmail CustomerPhone    Status  OrderDate  \\\n",
       "0                 flor.stone@raytheon.com   13171234104   Shipped  17-Nov-16   \n",
       "1    lavera.emerson@plainsallamerican.com   13171234111   Shipped  20-Feb-17   \n",
       "2                   fern.head@usfoods.com   18121234115  Canceled  03-Jan-17   \n",
       "3                  shyla.ortiz@abbvie.com   13171234126   Pending  15-Oct-17   \n",
       "4                   jeni.levy@centene.com   18121214129   Shipped  09-Apr-17   \n",
       "..                                    ...           ...       ...        ...   \n",
       "395                 VegaVincent@gmail.com     787879874   Shipped  27-Sep-17   \n",
       "396              VillanuevaNoah@gmail.com     785811219   Pending  16-Aug-16   \n",
       "397               VoldemortLord@gmail.com     789243757  Canceled  27-May-16   \n",
       "398               LucyCechtelar@gmail.com     964940981   Shipped  27-May-17   \n",
       "399                    JohnSnow@gmail.com     567897474  Canceled  27-May-17   \n",
       "\n",
       "     OrderItemQuantity PerUnitPrice TotalItemQuantity  \n",
       "0                  132       469.99               122  \n",
       "1                  124       519.99               123  \n",
       "2                   92       800.74               123  \n",
       "3                  128       849.99               124  \n",
       "4                  106       109.99               125  \n",
       "..                 ...          ...               ...  \n",
       "395                 32       725.99               107  \n",
       "396                 66       798.26               118  \n",
       "397                 82       849.99               118  \n",
       "398                157       821.99                95  \n",
       "399                 32       579.59                92  \n",
       "\n",
       "[400 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e5c8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'Profit'\n",
    "y = df[TARGET_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d54a5832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      542.95\n",
       "1      448.71\n",
       "2      625.54\n",
       "3      410.59\n",
       "4      489.58\n",
       "        ...  \n",
       "395    185.63\n",
       "396    168.84\n",
       "397    121.04\n",
       "398    147.64\n",
       "399     96.81\n",
       "Name: Profit, Length: 400, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31328771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection and Data Leakage Mitigation\n",
    "COLUMNS_TO_DROP = [\n",
    "    'CustomerName', 'CustomerAddress', 'CustomerEmail', 'CustomerPhone',\n",
    "    'EmployeeName', 'EmployeeEmail', 'EmployeePhone', 'EmployeeHireDate',\n",
    "    'WarehouseAddress', 'WarehouseName', 'PostalCode',\n",
    "    'ProductStandardCost', 'ProductListPrice' # Data Leakage\n",
    "]\n",
    "\n",
    "X = df.drop(COLUMNS_TO_DROP + [TARGET_COLUMN], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ebaba9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "      <th>CountryName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>EmployeeJobTitle</th>\n",
       "      <th>CategoryName</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>ProductDescription</th>\n",
       "      <th>CustomerCreditLimit</th>\n",
       "      <th>Status</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>OrderItemQuantity</th>\n",
       "      <th>PerUnitPrice</th>\n",
       "      <th>TotalItemQuantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Public Accountant</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2699 V3 (OEM/Tray)</td>\n",
       "      <td>Speed:2.3GHz,Cores:18,TDP:145W</td>\n",
       "      <td>5000</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>17-Nov-16</td>\n",
       "      <td>132</td>\n",
       "      <td>469.99</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2697 V3</td>\n",
       "      <td>Speed:2.6GHz,Cores:14</td>\n",
       "      <td>5000</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>20-Feb-17</td>\n",
       "      <td>124</td>\n",
       "      <td>519.99</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Administration Assistant</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2698 V3 (OEM/Tray)</td>\n",
       "      <td>Speed:2.3GHz</td>\n",
       "      <td>1200</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>03-Jan-17</td>\n",
       "      <td>92</td>\n",
       "      <td>800.74</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>President</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2697 V4</td>\n",
       "      <td>Cores:18,TDP:145W</td>\n",
       "      <td>2400</td>\n",
       "      <td>Pending</td>\n",
       "      <td>15-Oct-17</td>\n",
       "      <td>128</td>\n",
       "      <td>849.99</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Administration Vice President</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2685 V3 (OEM/Tray)</td>\n",
       "      <td>Speed:2.6GHz,Cores:12</td>\n",
       "      <td>1200</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>09-Apr-17</td>\n",
       "      <td>106</td>\n",
       "      <td>109.99</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Clerk</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>MSI GTX 1080 TI LIGHTNING Z</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>4900</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>27-Sep-17</td>\n",
       "      <td>32</td>\n",
       "      <td>725.99</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>Asus ROG-POSEIDON-GTX1080TI-P11G-GAMING</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>5000</td>\n",
       "      <td>Pending</td>\n",
       "      <td>16-Aug-16</td>\n",
       "      <td>66</td>\n",
       "      <td>798.26</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>MSI GTX 1080 TI LIGHTNING X</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>4000</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>27-May-16</td>\n",
       "      <td>82</td>\n",
       "      <td>849.99</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>Zotac ZT-P10810A-10P</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>3000</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>27-May-17</td>\n",
       "      <td>157</td>\n",
       "      <td>821.99</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>MSI GAMING</td>\n",
       "      <td>Chipset:GeForce GTX 780 Ti</td>\n",
       "      <td>2000</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>27-May-17</td>\n",
       "      <td>32</td>\n",
       "      <td>579.59</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegionName               CountryName        State       City  \\\n",
       "0    South America  United States of America        Texas  Southlake   \n",
       "1    South America  United States of America        Texas  Southlake   \n",
       "2    South America  United States of America        Texas  Southlake   \n",
       "3    South America  United States of America        Texas  Southlake   \n",
       "4    South America  United States of America        Texas  Southlake   \n",
       "..             ...                       ...          ...        ...   \n",
       "395           Asia                     India  Maharashtra     Bombay   \n",
       "396           Asia                     India  Maharashtra     Bombay   \n",
       "397           Asia                     India  Maharashtra     Bombay   \n",
       "398           Asia                     India  Maharashtra     Bombay   \n",
       "399           Asia                     India  Maharashtra     Bombay   \n",
       "\n",
       "                  EmployeeJobTitle CategoryName  \\\n",
       "0                Public Accountant          CPU   \n",
       "1               Accounting Manager          CPU   \n",
       "2         Administration Assistant          CPU   \n",
       "3                        President          CPU   \n",
       "4    Administration Vice President          CPU   \n",
       "..                             ...          ...   \n",
       "395                    Stock Clerk   Video Card   \n",
       "396                  Stock Manager   Video Card   \n",
       "397                  Stock Manager   Video Card   \n",
       "398                  Stock Manager   Video Card   \n",
       "399                  Stock Manager   Video Card   \n",
       "\n",
       "                                 ProductName              ProductDescription  \\\n",
       "0           Intel Xeon E5-2699 V3 (OEM/Tray)  Speed:2.3GHz,Cores:18,TDP:145W   \n",
       "1                      Intel Xeon E5-2697 V3           Speed:2.6GHz,Cores:14   \n",
       "2           Intel Xeon E5-2698 V3 (OEM/Tray)                    Speed:2.3GHz   \n",
       "3                      Intel Xeon E5-2697 V4               Cores:18,TDP:145W   \n",
       "4           Intel Xeon E5-2685 V3 (OEM/Tray)           Speed:2.6GHz,Cores:12   \n",
       "..                                       ...                             ...   \n",
       "395              MSI GTX 1080 TI LIGHTNING Z     Chipset:GeForce GTX 1080 Ti   \n",
       "396  Asus ROG-POSEIDON-GTX1080TI-P11G-GAMING     Chipset:GeForce GTX 1080 Ti   \n",
       "397              MSI GTX 1080 TI LIGHTNING X     Chipset:GeForce GTX 1080 Ti   \n",
       "398                     Zotac ZT-P10810A-10P     Chipset:GeForce GTX 1080 Ti   \n",
       "399                               MSI GAMING      Chipset:GeForce GTX 780 Ti   \n",
       "\n",
       "     CustomerCreditLimit    Status  OrderDate  OrderItemQuantity  \\\n",
       "0                   5000   Shipped  17-Nov-16                132   \n",
       "1                   5000   Shipped  20-Feb-17                124   \n",
       "2                   1200  Canceled  03-Jan-17                 92   \n",
       "3                   2400   Pending  15-Oct-17                128   \n",
       "4                   1200   Shipped  09-Apr-17                106   \n",
       "..                   ...       ...        ...                ...   \n",
       "395                 4900   Shipped  27-Sep-17                 32   \n",
       "396                 5000   Pending  16-Aug-16                 66   \n",
       "397                 4000  Canceled  27-May-16                 82   \n",
       "398                 3000   Shipped  27-May-17                157   \n",
       "399                 2000  Canceled  27-May-17                 32   \n",
       "\n",
       "     PerUnitPrice  TotalItemQuantity  \n",
       "0          469.99                122  \n",
       "1          519.99                123  \n",
       "2          800.74                123  \n",
       "3          849.99                124  \n",
       "4          109.99                125  \n",
       "..            ...                ...  \n",
       "395        725.99                107  \n",
       "396        798.26                118  \n",
       "397        849.99                118  \n",
       "398        821.99                 95  \n",
       "399        579.59                 92  \n",
       "\n",
       "[400 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4788b8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (400, 28)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c372a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering (Temporal Data)\n",
    "# Convert OrderDate to datetime and extract useful features\n",
    "X['OrderDate'] = pd.to_datetime(X['OrderDate'], format='%d-%b-%y')\n",
    "X['Order_Month'] = X['OrderDate'].dt.month\n",
    "X['Order_Year'] = X['OrderDate'].dt.year\n",
    "X['Order_Weekday'] = X['OrderDate'].dt.dayofweek\n",
    "\n",
    "X = X.drop('OrderDate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0a3beb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "      <th>CountryName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>EmployeeJobTitle</th>\n",
       "      <th>CategoryName</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>ProductDescription</th>\n",
       "      <th>CustomerCreditLimit</th>\n",
       "      <th>Status</th>\n",
       "      <th>OrderItemQuantity</th>\n",
       "      <th>PerUnitPrice</th>\n",
       "      <th>TotalItemQuantity</th>\n",
       "      <th>Order_Month</th>\n",
       "      <th>Order_Year</th>\n",
       "      <th>Order_Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Public Accountant</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2699 V3 (OEM/Tray)</td>\n",
       "      <td>Speed:2.3GHz,Cores:18,TDP:145W</td>\n",
       "      <td>5000</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>132</td>\n",
       "      <td>469.99</td>\n",
       "      <td>122</td>\n",
       "      <td>11</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2697 V3</td>\n",
       "      <td>Speed:2.6GHz,Cores:14</td>\n",
       "      <td>5000</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>124</td>\n",
       "      <td>519.99</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Administration Assistant</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2698 V3 (OEM/Tray)</td>\n",
       "      <td>Speed:2.3GHz</td>\n",
       "      <td>1200</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>92</td>\n",
       "      <td>800.74</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>President</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2697 V4</td>\n",
       "      <td>Cores:18,TDP:145W</td>\n",
       "      <td>2400</td>\n",
       "      <td>Pending</td>\n",
       "      <td>128</td>\n",
       "      <td>849.99</td>\n",
       "      <td>124</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Administration Vice President</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2685 V3 (OEM/Tray)</td>\n",
       "      <td>Speed:2.6GHz,Cores:12</td>\n",
       "      <td>1200</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>106</td>\n",
       "      <td>109.99</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Clerk</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>MSI GTX 1080 TI LIGHTNING Z</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>4900</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>32</td>\n",
       "      <td>725.99</td>\n",
       "      <td>107</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>Asus ROG-POSEIDON-GTX1080TI-P11G-GAMING</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>5000</td>\n",
       "      <td>Pending</td>\n",
       "      <td>66</td>\n",
       "      <td>798.26</td>\n",
       "      <td>118</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>MSI GTX 1080 TI LIGHTNING X</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>4000</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>82</td>\n",
       "      <td>849.99</td>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>Zotac ZT-P10810A-10P</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>3000</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>157</td>\n",
       "      <td>821.99</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>MSI GAMING</td>\n",
       "      <td>Chipset:GeForce GTX 780 Ti</td>\n",
       "      <td>2000</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>32</td>\n",
       "      <td>579.59</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegionName               CountryName        State       City  \\\n",
       "0    South America  United States of America        Texas  Southlake   \n",
       "1    South America  United States of America        Texas  Southlake   \n",
       "2    South America  United States of America        Texas  Southlake   \n",
       "3    South America  United States of America        Texas  Southlake   \n",
       "4    South America  United States of America        Texas  Southlake   \n",
       "..             ...                       ...          ...        ...   \n",
       "395           Asia                     India  Maharashtra     Bombay   \n",
       "396           Asia                     India  Maharashtra     Bombay   \n",
       "397           Asia                     India  Maharashtra     Bombay   \n",
       "398           Asia                     India  Maharashtra     Bombay   \n",
       "399           Asia                     India  Maharashtra     Bombay   \n",
       "\n",
       "                  EmployeeJobTitle CategoryName  \\\n",
       "0                Public Accountant          CPU   \n",
       "1               Accounting Manager          CPU   \n",
       "2         Administration Assistant          CPU   \n",
       "3                        President          CPU   \n",
       "4    Administration Vice President          CPU   \n",
       "..                             ...          ...   \n",
       "395                    Stock Clerk   Video Card   \n",
       "396                  Stock Manager   Video Card   \n",
       "397                  Stock Manager   Video Card   \n",
       "398                  Stock Manager   Video Card   \n",
       "399                  Stock Manager   Video Card   \n",
       "\n",
       "                                 ProductName              ProductDescription  \\\n",
       "0           Intel Xeon E5-2699 V3 (OEM/Tray)  Speed:2.3GHz,Cores:18,TDP:145W   \n",
       "1                      Intel Xeon E5-2697 V3           Speed:2.6GHz,Cores:14   \n",
       "2           Intel Xeon E5-2698 V3 (OEM/Tray)                    Speed:2.3GHz   \n",
       "3                      Intel Xeon E5-2697 V4               Cores:18,TDP:145W   \n",
       "4           Intel Xeon E5-2685 V3 (OEM/Tray)           Speed:2.6GHz,Cores:12   \n",
       "..                                       ...                             ...   \n",
       "395              MSI GTX 1080 TI LIGHTNING Z     Chipset:GeForce GTX 1080 Ti   \n",
       "396  Asus ROG-POSEIDON-GTX1080TI-P11G-GAMING     Chipset:GeForce GTX 1080 Ti   \n",
       "397              MSI GTX 1080 TI LIGHTNING X     Chipset:GeForce GTX 1080 Ti   \n",
       "398                     Zotac ZT-P10810A-10P     Chipset:GeForce GTX 1080 Ti   \n",
       "399                               MSI GAMING      Chipset:GeForce GTX 780 Ti   \n",
       "\n",
       "     CustomerCreditLimit    Status  OrderItemQuantity  PerUnitPrice  \\\n",
       "0                   5000   Shipped                132        469.99   \n",
       "1                   5000   Shipped                124        519.99   \n",
       "2                   1200  Canceled                 92        800.74   \n",
       "3                   2400   Pending                128        849.99   \n",
       "4                   1200   Shipped                106        109.99   \n",
       "..                   ...       ...                ...           ...   \n",
       "395                 4900   Shipped                 32        725.99   \n",
       "396                 5000   Pending                 66        798.26   \n",
       "397                 4000  Canceled                 82        849.99   \n",
       "398                 3000   Shipped                157        821.99   \n",
       "399                 2000  Canceled                 32        579.59   \n",
       "\n",
       "     TotalItemQuantity  Order_Month  Order_Year  Order_Weekday  \n",
       "0                  122           11        2016              3  \n",
       "1                  123            2        2017              0  \n",
       "2                  123            1        2017              1  \n",
       "3                  124           10        2017              6  \n",
       "4                  125            4        2017              6  \n",
       "..                 ...          ...         ...            ...  \n",
       "395                107            9        2017              2  \n",
       "396                118            8        2016              1  \n",
       "397                118            5        2016              4  \n",
       "398                 95            5        2017              5  \n",
       "399                 92            5        2017              5  \n",
       "\n",
       "[400 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "735ffd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "NUMERICAL_FEATURES = ['CustomerCreditLimit', 'OrderItemQuantity', 'TotalItemQuantity', 'Order_Month', 'Order_Year', 'Order_Weekday']\n",
    "CATEGORICAL_FEATURES = X.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0a1d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d02ed8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "          transformers=[\n",
    "                    ('num', StandardScaler(), NUMERICAL_FEATURES),\n",
    "                    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), CATEGORICAL_FEATURES)\n",
    "          ],\n",
    "          remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71200e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "Processed feature count (Input Dimension): 498\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing data...\")\n",
    "X_train = preprocessor.fit_transform(X_train_raw)\n",
    "X_test = preprocessor.transform(X_test_raw)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "print(f\"Processed feature count (Input Dimension): {input_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa61dd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.93470588e-01,  1.20495243e+00, -2.06006865e-02, ...,\n",
       "         1.00000000e+00,  0.00000000e+00,  8.49990000e+02],\n",
       "       [-8.99981044e-01, -2.74234458e-01, -6.56500237e-02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  8.99990000e+02],\n",
       "       [-5.78377623e-01, -3.34609433e-01,  1.07559985e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  6.68900000e+01],\n",
       "       ...,\n",
       "       [-9.64301728e-01,  1.11438997e+00,  7.90287383e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.89999000e+03],\n",
       "       [ 7.08036062e-01, -3.34609433e-01,  1.31586298e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.46996000e+03],\n",
       "       [ 1.93470588e-01, -7.57234259e-01, -1.77752484e+00, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.46996000e+03]],\n",
       "      shape=(320, 498))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4feec180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15726378e+00, -1.66285889e+00, -4.41061167e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.13990000e+02],\n",
       "       [ 1.29149904e-01,  5.40827707e-01,  8.65369611e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.95720000e+02],\n",
       "       [ 2.57791272e-01, -1.42135899e+00,  8.65369611e-01, ...,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.73990000e+02],\n",
       "       ...,\n",
       "       [-1.15726378e+00,  7.21952633e-01,  1.27081365e+00, ...,\n",
       "         1.00000000e+00,  0.00000000e+00,  6.44000000e+02],\n",
       "       [-1.09294310e+00,  1.44645234e+00, -2.75880264e-01, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  4.39900000e+01],\n",
       "       [-3.85415570e-01,  9.03077559e-01,  8.95402503e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.49900000e+01]],\n",
       "      shape=(80, 498))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac1aef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Deep Learning Architectures (With L2 Regularization)\n",
    "L2_REG = 0.001 # Define L2 regularization strength\n",
    "\n",
    "def build_simple_dnn(input_dim):\n",
    "          \"\"\"A baseline, shallow neural network with L2 regularization.\"\"\"\n",
    "          model = Sequential([\n",
    "                    Input(shape=(input_dim,)),\n",
    "                    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(1, activation='linear') # Linear activation for regression\n",
    "          ], name=\"Simple_DNN_3_Layers_L2\")\n",
    "          return model\n",
    "\n",
    "def build_deep_dnn(input_dim):\n",
    "          \"\"\"A deeper network with L2 regulariation and increased capacity (6 layers).\"\"\"\n",
    "          model = Sequential([\n",
    "                    Input(shape=(input_dim,)),\n",
    "                    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(1, activation='linear')\n",
    "          ], name=\"Deep_DNN_6_Layers_L2\")\n",
    "          return model\n",
    "\n",
    "def build_regularized_dnn(input_dim):\n",
    "          \"\"\"Deep network with Dropout, BatchNormalization and L2 regularization.\"\"\"\n",
    "          model = Sequential([\n",
    "                    Input(shape=(input_dim,)),\n",
    "                    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.3),\n",
    "                    \n",
    "                    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.3),\n",
    "                    \n",
    "                    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(1, activation='linear')\n",
    "          ], name=\"Regularized_DNN_Robust\")\n",
    "          return model\n",
    "\n",
    "def build_wide_network(input_dim):\n",
    "          \"\"\"A very wide network with fewer layers and L2 regularization.\"\"\"\n",
    "          model = Sequential([\n",
    "                    Input(shape=(input_dim,)),\n",
    "                    Dense(512, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dropout(0.2),\n",
    "                    Dense(1, activation='linear')\n",
    "          ], name=\"Wide_Network_L2\")\n",
    "          return model\n",
    "\n",
    "# Dictionary of model builders\n",
    "model_builders = [\n",
    "          build_simple_dnn,\n",
    "          build_deep_dnn,\n",
    "          build_regularized_dnn,\n",
    "          build_wide_network\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37956e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING TENSORFLOW MODEL TRAINING\n",
      "================================================================================\n",
      "\n",
      "Training Simple_DNN_3_Layers_L2...\n",
      "Epoch 1/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 150.2293 - mae: 150.5773 - val_loss: 199.0816 - val_mae: 199.4360 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 147.1069 - mae: 147.4641 - val_loss: 197.3477 - val_mae: 197.7109 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 147.1705 - mae: 147.5340 - val_loss: 197.1902 - val_mae: 197.5616 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 146.7309 - mae: 147.1032 - val_loss: 197.5052 - val_mae: 197.8840 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 146.1873 - mae: 146.5673 - val_loss: 198.1063 - val_mae: 198.4917 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.0082 - mae: 146.3958 - val_loss: 198.9641 - val_mae: 199.3554 - learning_rate: 0.0010\n",
      "Epoch 7/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.9540 - mae: 146.3474 - val_loss: 199.5269 - val_mae: 199.9234 - learning_rate: 0.0010\n",
      "Epoch 8/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 132.0399 - mae: 132.4365\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.0258 - mae: 146.4239 - val_loss: 199.4231 - val_mae: 199.8242 - learning_rate: 0.0010\n",
      "Epoch 9/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.9339 - mae: 146.3358 - val_loss: 199.1281 - val_mae: 199.5312 - learning_rate: 5.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.8527 - mae: 146.2558 - val_loss: 198.8130 - val_mae: 199.2180 - learning_rate: 5.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 145.7896 - mae: 146.1947 - val_loss: 198.5705 - val_mae: 198.9772 - learning_rate: 5.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.7292 - mae: 146.1360 - val_loss: 198.4468 - val_mae: 198.8551 - learning_rate: 5.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 131.5365 - mae: 131.9448\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 145.6672 - mae: 146.0759 - val_loss: 198.4426 - val_mae: 198.8523 - learning_rate: 5.0000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 145.6115 - mae: 146.0198 - val_loss: 198.4722 - val_mae: 198.8827 - learning_rate: 2.5000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.5863 - mae: 145.9969 - val_loss: 198.5024 - val_mae: 198.9135 - learning_rate: 2.5000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.5640 - mae: 145.9753 - val_loss: 198.5204 - val_mae: 198.9322 - learning_rate: 2.5000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.5415 - mae: 145.9534 - val_loss: 198.5279 - val_mae: 198.9403 - learning_rate: 2.5000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 131.3992 - mae: 131.8115\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.5182 - mae: 145.9308 - val_loss: 198.5278 - val_mae: 198.9407 - learning_rate: 2.5000e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.4934 - mae: 145.9063 - val_loss: 198.5244 - val_mae: 198.9375 - learning_rate: 1.2500e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.4810 - mae: 145.8942 - val_loss: 198.5176 - val_mae: 198.9310 - learning_rate: 1.2500e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.4665 - mae: 145.8800 - val_loss: 198.5007 - val_mae: 198.9144 - learning_rate: 1.2500e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.4522 - mae: 145.8659 - val_loss: 198.4743 - val_mae: 198.8882 - learning_rate: 1.2500e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 131.3041 - mae: 131.7179\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.4362 - mae: 145.8502 - val_loss: 198.4618 - val_mae: 198.8760 - learning_rate: 1.2500e-04\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Evalutaing Simple_DNN_3_Layers_L2 on Test Set...\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "Training Deep_DNN_6_Layers_L2...\n",
      "Epoch 1/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 156.5959 - mae: 156.4154 - val_loss: 199.0583 - val_mae: 198.9109 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 148.7897 - mae: 148.6604 - val_loss: 197.5884 - val_mae: 197.4882 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 147.8882 - mae: 147.8024 - val_loss: 198.0405 - val_mae: 197.9833 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.3886 - mae: 146.3464 - val_loss: 200.2185 - val_mae: 200.2004 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 132.7787 - mae: 132.7607\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.9176 - mae: 146.9131 - val_loss: 200.5112 - val_mae: 200.5287 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 146.8177 - mae: 146.8392 - val_loss: 199.6935 - val_mae: 199.7274 - learning_rate: 5.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.6010 - mae: 146.6394 - val_loss: 198.8544 - val_mae: 198.9038 - learning_rate: 5.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 146.5505 - mae: 146.6053 - val_loss: 198.4420 - val_mae: 198.5059 - learning_rate: 5.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.4817 - mae: 146.5508 - val_loss: 198.3410 - val_mae: 198.4186 - learning_rate: 5.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 132.1760 - mae: 132.2537\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 146.3972 - mae: 146.4798 - val_loss: 198.4558 - val_mae: 198.5464 - learning_rate: 5.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.3228 - mae: 146.4157 - val_loss: 198.5695 - val_mae: 198.6663 - learning_rate: 2.5000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.2732 - mae: 146.3721 - val_loss: 198.7361 - val_mae: 198.8387 - learning_rate: 2.5000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 146.2156 - mae: 146.3205 - val_loss: 198.9528 - val_mae: 199.0612 - learning_rate: 2.5000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 146.1784 - mae: 146.2889 - val_loss: 199.1387 - val_mae: 199.2527 - learning_rate: 2.5000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 132.1139 - mae: 132.2279\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 146.1628 - mae: 146.2787 - val_loss: 199.2430 - val_mae: 199.3623 - learning_rate: 2.5000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 146.1459 - mae: 146.2631 - val_loss: 199.2488 - val_mae: 199.3707 - learning_rate: 1.2500e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 146.1378 - mae: 146.2578 - val_loss: 199.2125 - val_mae: 199.3370 - learning_rate: 1.2500e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 146.1259 - mae: 146.2500 - val_loss: 199.1553 - val_mae: 199.2823 - learning_rate: 1.2500e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 146.1112 - mae: 146.2387 - val_loss: 199.0990 - val_mae: 199.2286 - learning_rate: 1.2500e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 132.0244 - mae: 132.1537\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.0952 - mae: 146.2256 - val_loss: 199.0528 - val_mae: 199.1848 - learning_rate: 1.2500e-04\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Evalutaing Deep_DNN_6_Layers_L2 on Test Set...\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "Training Regularized_DNN_Robust...\n",
      "Epoch 1/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 173.1714 - mae: 173.0805 - val_loss: 214.5925 - val_mae: 214.5185 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 171.6664 - mae: 171.5993 - val_loss: 213.8684 - val_mae: 213.8021 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 170.2793 - mae: 170.2267 - val_loss: 213.0400 - val_mae: 212.9975 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 168.7742 - mae: 168.7351 - val_loss: 213.0938 - val_mae: 213.0667 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 146.6799 - mae: 146.6528\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 167.4592 - mae: 167.4347 - val_loss: 213.4066 - val_mae: 213.3884 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 166.6387 - mae: 166.6269 - val_loss: 213.8675 - val_mae: 213.8586 - learning_rate: 5.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 165.9988 - mae: 165.9930 - val_loss: 214.3599 - val_mae: 214.3577 - learning_rate: 5.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 165.0609 - mae: 165.0597 - val_loss: 214.9850 - val_mae: 214.9884 - learning_rate: 5.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 164.5600 - mae: 164.5637 - val_loss: 215.2165 - val_mae: 215.2251 - learning_rate: 5.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 142.7671 - mae: 142.7757\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 163.9107 - mae: 163.9199 - val_loss: 215.5384 - val_mae: 215.5519 - learning_rate: 5.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 163.2824 - mae: 163.2934 - val_loss: 215.5944 - val_mae: 215.6103 - learning_rate: 2.5000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 163.2124 - mae: 163.2291 - val_loss: 215.6997 - val_mae: 215.7180 - learning_rate: 2.5000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 162.4698 - mae: 162.4880 - val_loss: 215.6794 - val_mae: 215.6999 - learning_rate: 2.5000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 162.0995 - mae: 162.1208 - val_loss: 215.5650 - val_mae: 215.5876 - learning_rate: 2.5000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 140.9229 - mae: 140.9455\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 162.1882 - mae: 162.2108 - val_loss: 215.5211 - val_mae: 215.5460 - learning_rate: 2.5000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 161.5590 - mae: 161.5841 - val_loss: 215.4463 - val_mae: 215.4702 - learning_rate: 1.2500e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 161.4904 - mae: 161.5162 - val_loss: 215.3415 - val_mae: 215.3649 - learning_rate: 1.2500e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 161.5027 - mae: 161.5296 - val_loss: 215.3036 - val_mae: 215.3259 - learning_rate: 1.2500e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 161.0582 - mae: 161.0865 - val_loss: 215.2304 - val_mae: 215.2593 - learning_rate: 1.2500e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 140.1153 - mae: 140.1442\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 160.9588 - mae: 160.9880 - val_loss: 215.1939 - val_mae: 215.2238 - learning_rate: 1.2500e-04\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Evalutaing Regularized_DNN_Robust on Test Set...\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C1FF4E9800> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/stepWARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C1FF4E9800> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "Training Wide_Network_L2...\n",
      "Epoch 1/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 151.1620 - mae: 151.1786 - val_loss: 197.3803 - val_mae: 197.4308 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 153.3026 - mae: 153.3696 - val_loss: 197.1917 - val_mae: 197.2793 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 146.5646 - mae: 146.6729 - val_loss: 198.6986 - val_mae: 198.8297 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 148.4152 - mae: 148.5585 - val_loss: 198.8559 - val_mae: 199.0186 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 134.6587 - mae: 134.8147\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 148.1672 - mae: 148.3369 - val_loss: 197.4115 - val_mae: 197.6010 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 147.1414 - mae: 147.3335 - val_loss: 196.8576 - val_mae: 197.0586 - learning_rate: 5.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 147.7301 - mae: 147.9351 - val_loss: 196.7549 - val_mae: 196.9663 - learning_rate: 5.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.4898 - mae: 145.7048 - val_loss: 196.8006 - val_mae: 197.0214 - learning_rate: 5.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.5854 - mae: 145.8065 - val_loss: 197.1081 - val_mae: 197.3373 - learning_rate: 5.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 147.2142 - mae: 147.4464 - val_loss: 196.9310 - val_mae: 197.1678 - learning_rate: 5.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 149.6057 - mae: 149.8422 - val_loss: 196.5684 - val_mae: 196.8070 - learning_rate: 5.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.3828 - mae: 145.6255 - val_loss: 196.6515 - val_mae: 196.9008 - learning_rate: 5.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 147.7187 - mae: 147.9677 - val_loss: 196.6437 - val_mae: 196.8982 - learning_rate: 5.0000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 142.9854 - mae: 143.2398 - val_loss: 196.6467 - val_mae: 196.9056 - learning_rate: 5.0000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 146.9846 - mae: 147.2421 - val_loss: 196.6228 - val_mae: 196.8855 - learning_rate: 5.0000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 143.8894 - mae: 144.1528 - val_loss: 196.1586 - val_mae: 196.4224 - learning_rate: 5.0000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 147.6839 - mae: 147.9506 - val_loss: 196.0036 - val_mae: 196.2650 - learning_rate: 5.0000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.2477 - mae: 145.5163 - val_loss: 195.7698 - val_mae: 196.0341 - learning_rate: 5.0000e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.2747 - mae: 145.5452 - val_loss: 195.7119 - val_mae: 195.9827 - learning_rate: 5.0000e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.1473 - mae: 146.4191 - val_loss: 195.6617 - val_mae: 195.9262 - learning_rate: 5.0000e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.5175 - mae: 145.7899 - val_loss: 195.4150 - val_mae: 195.6837 - learning_rate: 5.0000e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 147.7441 - mae: 148.0166 - val_loss: 195.5356 - val_mae: 195.8080 - learning_rate: 5.0000e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.3899 - mae: 145.6613 - val_loss: 195.6856 - val_mae: 195.9574 - learning_rate: 5.0000e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 144.2651 - mae: 144.5350 - val_loss: 195.5063 - val_mae: 195.7771 - learning_rate: 5.0000e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.2059 - mae: 145.4736 - val_loss: 194.6895 - val_mae: 194.9589 - learning_rate: 5.0000e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.4520 - mae: 146.7197 - val_loss: 194.5395 - val_mae: 194.8071 - learning_rate: 5.0000e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 146.2908 - mae: 146.5570 - val_loss: 194.7785 - val_mae: 195.0395 - learning_rate: 5.0000e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 141.8618 - mae: 142.1264 - val_loss: 195.4723 - val_mae: 195.7353 - learning_rate: 5.0000e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 142.3334 - mae: 142.5927 - val_loss: 195.1209 - val_mae: 195.3810 - learning_rate: 5.0000e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 143.9474 - mae: 144.2052 - val_loss: 194.3423 - val_mae: 194.5978 - learning_rate: 5.0000e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.3961 - mae: 146.6517 - val_loss: 193.8793 - val_mae: 194.1327 - learning_rate: 5.0000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 144.2401 - mae: 144.4910 - val_loss: 193.5016 - val_mae: 193.7511 - learning_rate: 5.0000e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 142.2069 - mae: 142.4549 - val_loss: 193.8160 - val_mae: 194.0614 - learning_rate: 5.0000e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 143.6697 - mae: 143.9135 - val_loss: 194.0822 - val_mae: 194.3232 - learning_rate: 5.0000e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 143.9373 - mae: 144.1740 - val_loss: 193.8082 - val_mae: 194.0445 - learning_rate: 5.0000e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 142.5743 - mae: 142.8076 - val_loss: 193.5577 - val_mae: 193.7860 - learning_rate: 5.0000e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 144.0825 - mae: 144.3087 - val_loss: 193.2991 - val_mae: 193.5237 - learning_rate: 5.0000e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 144.2270 - mae: 144.4509 - val_loss: 192.9719 - val_mae: 193.1915 - learning_rate: 5.0000e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 143.9983 - mae: 144.2152 - val_loss: 192.8010 - val_mae: 193.0148 - learning_rate: 5.0000e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 143.7885 - mae: 143.9994 - val_loss: 192.5561 - val_mae: 192.7624 - learning_rate: 5.0000e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 143.4633 - mae: 143.6675 - val_loss: 192.6994 - val_mae: 192.8980 - learning_rate: 5.0000e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 140.9646 - mae: 141.1630 - val_loss: 192.9831 - val_mae: 193.1786 - learning_rate: 5.0000e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 141.1922 - mae: 141.3839 - val_loss: 192.6533 - val_mae: 192.8419 - learning_rate: 5.0000e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 141.8960 - mae: 142.0799 - val_loss: 191.8544 - val_mae: 192.0288 - learning_rate: 5.0000e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 142.0753 - mae: 142.2512 - val_loss: 191.3921 - val_mae: 191.5660 - learning_rate: 5.0000e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 140.3754 - mae: 140.5465 - val_loss: 191.1856 - val_mae: 191.3516 - learning_rate: 5.0000e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 140.1777 - mae: 140.3411 - val_loss: 190.9993 - val_mae: 191.1575 - learning_rate: 5.0000e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 137.5387 - mae: 137.6920 - val_loss: 190.9862 - val_mae: 191.1367 - learning_rate: 5.0000e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 141.2269 - mae: 141.3731 - val_loss: 191.2706 - val_mae: 191.4117 - learning_rate: 5.0000e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 139.3907 - mae: 139.5290 - val_loss: 190.5448 - val_mae: 190.6788 - learning_rate: 5.0000e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 139.9160 - mae: 140.0460 - val_loss: 190.2780 - val_mae: 190.4035 - learning_rate: 5.0000e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 138.6440 - mae: 138.7641 - val_loss: 189.9984 - val_mae: 190.1147 - learning_rate: 5.0000e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 138.3728 - mae: 138.4862 - val_loss: 190.0043 - val_mae: 190.1102 - learning_rate: 5.0000e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 139.8362 - mae: 139.9396 - val_loss: 189.8863 - val_mae: 189.9849 - learning_rate: 5.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 139.5333 - mae: 139.6278 - val_loss: 189.7344 - val_mae: 189.8234 - learning_rate: 5.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 138.2191 - mae: 138.3011 - val_loss: 190.1522 - val_mae: 190.2315 - learning_rate: 5.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 136.5215 - mae: 136.5955 - val_loss: 188.8367 - val_mae: 188.9005 - learning_rate: 5.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 141.2200 - mae: 141.2842 - val_loss: 188.3843 - val_mae: 188.4432 - learning_rate: 5.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 137.3601 - mae: 137.4146 - val_loss: 188.2551 - val_mae: 188.3006 - learning_rate: 5.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 139.8805 - mae: 139.9231 - val_loss: 188.8755 - val_mae: 188.9132 - learning_rate: 5.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 136.9984 - mae: 137.0316 - val_loss: 189.1775 - val_mae: 189.2044 - learning_rate: 5.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 138.8261 - mae: 138.8474 - val_loss: 188.3890 - val_mae: 188.4048 - learning_rate: 5.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 137.1948 - mae: 137.2000 - val_loss: 187.2077 - val_mae: 187.2117 - learning_rate: 5.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 137.5895 - mae: 137.5889 - val_loss: 186.6370 - val_mae: 186.6293 - learning_rate: 5.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 134.8837 - mae: 134.8708 - val_loss: 186.9536 - val_mae: 186.9301 - learning_rate: 5.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 135.9140 - mae: 135.8870 - val_loss: 187.9785 - val_mae: 187.9471 - learning_rate: 5.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 135.5380 - mae: 135.5002 - val_loss: 187.2273 - val_mae: 187.1838 - learning_rate: 5.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 135.0335 - mae: 134.9845 - val_loss: 186.1237 - val_mae: 186.0591 - learning_rate: 5.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 135.3010 - mae: 135.2365 - val_loss: 185.5279 - val_mae: 185.4588 - learning_rate: 5.0000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 133.6346 - mae: 133.5577 - val_loss: 185.3714 - val_mae: 185.2892 - learning_rate: 5.0000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 133.2428 - mae: 133.1552 - val_loss: 185.9533 - val_mae: 185.8563 - learning_rate: 5.0000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 134.4803 - mae: 134.3787 - val_loss: 185.1905 - val_mae: 185.0739 - learning_rate: 5.0000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 133.8853 - mae: 133.7695 - val_loss: 184.3361 - val_mae: 184.2133 - learning_rate: 5.0000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 133.0262 - mae: 132.8945 - val_loss: 184.0112 - val_mae: 183.8744 - learning_rate: 5.0000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 132.2188 - mae: 132.0731 - val_loss: 184.3191 - val_mae: 184.1595 - learning_rate: 5.0000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 133.5991 - mae: 133.4424 - val_loss: 183.9516 - val_mae: 183.7804 - learning_rate: 5.0000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 130.5008 - mae: 130.3279 - val_loss: 183.7003 - val_mae: 183.5134 - learning_rate: 5.0000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 133.2225 - mae: 133.0361 - val_loss: 183.5361 - val_mae: 183.3270 - learning_rate: 5.0000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 133.8141 - mae: 133.6120 - val_loss: 183.1763 - val_mae: 182.9532 - learning_rate: 5.0000e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 130.0804 - mae: 129.8636 - val_loss: 183.1699 - val_mae: 182.9305 - learning_rate: 5.0000e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 131.8199 - mae: 131.5890 - val_loss: 182.4480 - val_mae: 182.1975 - learning_rate: 5.0000e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 130.0523 - mae: 129.8049 - val_loss: 181.5437 - val_mae: 181.2839 - learning_rate: 5.0000e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 132.2604 - mae: 131.9998 - val_loss: 182.0910 - val_mae: 181.8131 - learning_rate: 5.0000e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 131.3935 - mae: 131.1160 - val_loss: 182.1523 - val_mae: 181.8535 - learning_rate: 5.0000e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 130.2913 - mae: 129.9986 - val_loss: 180.5479 - val_mae: 180.2351 - learning_rate: 5.0000e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 128.9206 - mae: 128.6118 - val_loss: 179.8083 - val_mae: 179.4875 - learning_rate: 5.0000e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 129.9977 - mae: 129.6705 - val_loss: 180.1968 - val_mae: 179.8582 - learning_rate: 5.0000e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 128.8452 - mae: 128.5055 - val_loss: 180.3840 - val_mae: 180.0320 - learning_rate: 5.0000e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 129.2145 - mae: 128.8571 - val_loss: 179.0218 - val_mae: 178.6440 - learning_rate: 5.0000e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 126.3308 - mae: 125.9531 - val_loss: 179.1977 - val_mae: 178.8140 - learning_rate: 5.0000e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 128.8098 - mae: 128.4174 - val_loss: 178.5612 - val_mae: 178.1593 - learning_rate: 5.0000e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 124.0706 - mae: 123.6617 - val_loss: 178.2903 - val_mae: 177.8724 - learning_rate: 5.0000e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 127.6045 - mae: 127.1823 - val_loss: 178.4267 - val_mae: 177.9858 - learning_rate: 5.0000e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 125.3093 - mae: 124.8685 - val_loss: 177.3351 - val_mae: 176.8804 - learning_rate: 5.0000e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 125.5663 - mae: 125.1061 - val_loss: 176.6099 - val_mae: 176.1304 - learning_rate: 5.0000e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 123.9617 - mae: 123.4853 - val_loss: 177.0012 - val_mae: 176.5162 - learning_rate: 5.0000e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 124.9739 - mae: 124.4821 - val_loss: 178.0788 - val_mae: 177.5709 - learning_rate: 5.0000e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 126.1121 - mae: 125.6023 - val_loss: 176.3548 - val_mae: 175.8315 - learning_rate: 5.0000e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 123.9148 - mae: 123.3865 - val_loss: 174.9818 - val_mae: 174.4299 - learning_rate: 5.0000e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 124.8870 - mae: 124.3408 - val_loss: 175.5404 - val_mae: 174.9807 - learning_rate: 5.0000e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 124.9269 - mae: 124.3606 - val_loss: 175.6055 - val_mae: 175.0291 - learning_rate: 5.0000e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 123.1748 - mae: 122.5921 - val_loss: 174.0971 - val_mae: 173.5012 - learning_rate: 5.0000e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 121.8614 - mae: 121.2591 - val_loss: 174.3296 - val_mae: 173.7098 - learning_rate: 5.0000e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 123.3725 - mae: 122.7520 - val_loss: 173.9240 - val_mae: 173.2834 - learning_rate: 5.0000e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 123.5120 - mae: 122.8715 - val_loss: 172.7467 - val_mae: 172.0888 - learning_rate: 5.0000e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 121.6250 - mae: 120.9649 - val_loss: 172.2889 - val_mae: 171.6064 - learning_rate: 5.0000e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 122.5180 - mae: 121.8419 - val_loss: 172.1172 - val_mae: 171.4290 - learning_rate: 5.0000e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 120.2159 - mae: 119.5203 - val_loss: 172.1470 - val_mae: 171.4373 - learning_rate: 5.0000e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 123.1678 - mae: 122.4496 - val_loss: 171.1821 - val_mae: 170.4521 - learning_rate: 5.0000e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 122.4088 - mae: 121.6736 - val_loss: 170.7770 - val_mae: 170.0274 - learning_rate: 5.0000e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 118.4471 - mae: 117.6922 - val_loss: 170.4380 - val_mae: 169.6708 - learning_rate: 5.0000e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 118.0280 - mae: 117.2509 - val_loss: 170.0145 - val_mae: 169.2291 - learning_rate: 5.0000e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 120.0140 - mae: 119.2191 - val_loss: 169.6172 - val_mae: 168.8127 - learning_rate: 5.0000e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 117.4696 - mae: 116.6569 - val_loss: 169.8645 - val_mae: 169.0387 - learning_rate: 5.0000e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 119.6393 - mae: 118.8037 - val_loss: 168.7201 - val_mae: 167.8745 - learning_rate: 5.0000e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 118.8762 - mae: 118.0233 - val_loss: 168.3163 - val_mae: 167.4458 - learning_rate: 5.0000e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 118.8523 - mae: 117.9770 - val_loss: 168.7244 - val_mae: 167.8388 - learning_rate: 5.0000e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 117.8233 - mae: 116.9273 - val_loss: 167.6416 - val_mae: 166.7353 - learning_rate: 5.0000e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 117.3939 - mae: 116.4758 - val_loss: 167.1253 - val_mae: 166.1982 - learning_rate: 5.0000e-04\n",
      "Epoch 120/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 115.6953 - mae: 114.7554 - val_loss: 166.6535 - val_mae: 165.7054 - learning_rate: 5.0000e-04\n",
      "Epoch 121/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 113.3238 - mae: 112.3637 - val_loss: 166.1925 - val_mae: 165.2234 - learning_rate: 5.0000e-04\n",
      "Epoch 122/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 115.1031 - mae: 114.1260 - val_loss: 165.8138 - val_mae: 164.8237 - learning_rate: 5.0000e-04\n",
      "Epoch 123/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 112.9101 - mae: 111.9092 - val_loss: 165.9855 - val_mae: 164.9734 - learning_rate: 5.0000e-04\n",
      "Epoch 124/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 115.7868 - mae: 114.7640 - val_loss: 164.8873 - val_mae: 163.8475 - learning_rate: 5.0000e-04\n",
      "Epoch 125/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 116.5884 - mae: 115.5466 - val_loss: 164.4692 - val_mae: 163.4135 - learning_rate: 5.0000e-04\n",
      "Epoch 126/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 112.9315 - mae: 111.8667 - val_loss: 164.0941 - val_mae: 163.0195 - learning_rate: 5.0000e-04\n",
      "Epoch 127/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 113.4206 - mae: 112.3376 - val_loss: 163.7118 - val_mae: 162.6074 - learning_rate: 5.0000e-04\n",
      "Epoch 128/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 114.8569 - mae: 113.7465 - val_loss: 163.1458 - val_mae: 162.0218 - learning_rate: 5.0000e-04\n",
      "Epoch 129/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 113.8953 - mae: 112.7666 - val_loss: 162.8169 - val_mae: 161.6698 - learning_rate: 5.0000e-04\n",
      "Epoch 130/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 112.7041 - mae: 111.5535 - val_loss: 162.3899 - val_mae: 161.2275 - learning_rate: 5.0000e-04\n",
      "Epoch 131/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 112.7642 - mae: 111.5915 - val_loss: 161.9504 - val_mae: 160.7675 - learning_rate: 5.0000e-04\n",
      "Epoch 132/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 114.3838 - mae: 113.1900 - val_loss: 162.4617 - val_mae: 161.2574 - learning_rate: 5.0000e-04\n",
      "Epoch 133/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 110.6091 - mae: 109.3942 - val_loss: 161.1465 - val_mae: 159.9218 - learning_rate: 5.0000e-04\n",
      "Epoch 134/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 109.6565 - mae: 108.4232 - val_loss: 160.6866 - val_mae: 159.4408 - learning_rate: 5.0000e-04\n",
      "Epoch 135/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 109.6939 - mae: 108.4351 - val_loss: 160.2347 - val_mae: 158.9673 - learning_rate: 5.0000e-04\n",
      "Epoch 136/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 108.6155 - mae: 107.3393 - val_loss: 159.8403 - val_mae: 158.5508 - learning_rate: 5.0000e-04\n",
      "Epoch 137/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 110.3177 - mae: 109.0177 - val_loss: 159.3754 - val_mae: 158.0643 - learning_rate: 5.0000e-04\n",
      "Epoch 138/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 107.8102 - mae: 106.4872 - val_loss: 159.0978 - val_mae: 157.7612 - learning_rate: 5.0000e-04\n",
      "Epoch 139/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 107.8382 - mae: 106.4942 - val_loss: 158.7700 - val_mae: 157.4134 - learning_rate: 5.0000e-04\n",
      "Epoch 140/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 109.1343 - mae: 107.7704 - val_loss: 158.1236 - val_mae: 156.7478 - learning_rate: 5.0000e-04\n",
      "Epoch 141/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 107.1806 - mae: 105.7919 - val_loss: 157.7562 - val_mae: 156.3596 - learning_rate: 5.0000e-04\n",
      "Epoch 142/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 104.6332 - mae: 103.2250 - val_loss: 157.5819 - val_mae: 156.1622 - learning_rate: 5.0000e-04\n",
      "Epoch 143/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 108.5694 - mae: 107.1407 - val_loss: 156.9355 - val_mae: 155.4987 - learning_rate: 5.0000e-04\n",
      "Epoch 144/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 107.4193 - mae: 105.9747 - val_loss: 156.5710 - val_mae: 155.1029 - learning_rate: 5.0000e-04\n",
      "Epoch 145/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 105.0347 - mae: 103.5683 - val_loss: 157.1183 - val_mae: 155.6289 - learning_rate: 5.0000e-04\n",
      "Epoch 146/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 107.1267 - mae: 105.6384 - val_loss: 155.6603 - val_mae: 154.1607 - learning_rate: 5.0000e-04\n",
      "Epoch 147/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 106.1475 - mae: 104.6384 - val_loss: 155.2217 - val_mae: 153.7007 - learning_rate: 5.0000e-04\n",
      "Epoch 148/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 105.6718 - mae: 104.1408 - val_loss: 154.8476 - val_mae: 153.3006 - learning_rate: 5.0000e-04\n",
      "Epoch 149/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 104.2989 - mae: 102.7467 - val_loss: 154.4289 - val_mae: 152.8629 - learning_rate: 5.0000e-04\n",
      "Epoch 150/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 105.3937 - mae: 103.8226 - val_loss: 154.5305 - val_mae: 152.9479 - learning_rate: 5.0000e-04\n",
      "Epoch 151/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 103.4758 - mae: 101.8840 - val_loss: 153.5863 - val_mae: 151.9779 - learning_rate: 5.0000e-04\n",
      "Epoch 152/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 104.4021 - mae: 102.7895 - val_loss: 153.5926 - val_mae: 151.9639 - learning_rate: 5.0000e-04\n",
      "Epoch 153/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 104.6755 - mae: 103.0381 - val_loss: 153.3837 - val_mae: 151.7385 - learning_rate: 5.0000e-04\n",
      "Epoch 154/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 105.3099 - mae: 103.6541 - val_loss: 152.5131 - val_mae: 150.8473 - learning_rate: 5.0000e-04\n",
      "Epoch 155/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 102.7612 - mae: 101.0852 - val_loss: 152.1768 - val_mae: 150.4904 - learning_rate: 5.0000e-04\n",
      "Epoch 156/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 100.8114 - mae: 99.1123 - val_loss: 151.7614 - val_mae: 150.0525 - learning_rate: 5.0000e-04\n",
      "Epoch 157/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 102.9325 - mae: 101.2151 - val_loss: 151.9496 - val_mae: 150.2197 - learning_rate: 5.0000e-04\n",
      "Epoch 158/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 99.8010 - mae: 98.0629 - val_loss: 151.3171 - val_mae: 149.5689 - learning_rate: 5.0000e-04\n",
      "Epoch 159/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 101.6835 - mae: 99.9255 - val_loss: 150.8678 - val_mae: 149.0935 - learning_rate: 5.0000e-04\n",
      "Epoch 160/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 102.0492 - mae: 100.2699 - val_loss: 150.4209 - val_mae: 148.6298 - learning_rate: 5.0000e-04\n",
      "Epoch 161/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 102.3235 - mae: 100.5189 - val_loss: 149.8964 - val_mae: 148.0697 - learning_rate: 5.0000e-04\n",
      "Epoch 162/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 100.6474 - mae: 98.8264 - val_loss: 150.5251 - val_mae: 148.6911 - learning_rate: 5.0000e-04\n",
      "Epoch 163/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 101.3683 - mae: 99.5250 - val_loss: 149.6920 - val_mae: 147.8318 - learning_rate: 5.0000e-04\n",
      "Epoch 164/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 101.2944 - mae: 99.4279 - val_loss: 149.2145 - val_mae: 147.3381 - learning_rate: 5.0000e-04\n",
      "Epoch 165/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 99.1126 - mae: 97.2264 - val_loss: 148.5505 - val_mae: 146.6507 - learning_rate: 5.0000e-04\n",
      "Epoch 166/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 99.4936 - mae: 97.5872 - val_loss: 148.4890 - val_mae: 146.5711 - learning_rate: 5.0000e-04\n",
      "Epoch 167/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 98.8415 - mae: 96.9074 - val_loss: 148.0251 - val_mae: 146.0868 - learning_rate: 5.0000e-04\n",
      "Epoch 168/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 100.7174 - mae: 98.7687 - val_loss: 147.9432 - val_mae: 145.9791 - learning_rate: 5.0000e-04\n",
      "Epoch 169/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 97.8190 - mae: 95.8480 - val_loss: 149.8788 - val_mae: 147.8920 - learning_rate: 5.0000e-04\n",
      "Epoch 170/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 97.1730 - mae: 95.1833 - val_loss: 147.3511 - val_mae: 145.3503 - learning_rate: 5.0000e-04\n",
      "Epoch 171/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 97.9349 - mae: 95.9260 - val_loss: 146.8198 - val_mae: 144.7964 - learning_rate: 5.0000e-04\n",
      "Epoch 172/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 98.6281 - mae: 96.5998 - val_loss: 146.7584 - val_mae: 144.7195 - learning_rate: 5.0000e-04\n",
      "Epoch 173/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 97.8674 - mae: 95.8165 - val_loss: 146.2276 - val_mae: 144.1639 - learning_rate: 5.0000e-04\n",
      "Epoch 174/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 98.5293 - mae: 96.4546 - val_loss: 145.8386 - val_mae: 143.7524 - learning_rate: 5.0000e-04\n",
      "Epoch 175/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 98.3854 - mae: 96.2966 - val_loss: 146.2250 - val_mae: 144.1242 - learning_rate: 5.0000e-04\n",
      "Epoch 176/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 98.6532 - mae: 96.5404 - val_loss: 146.2624 - val_mae: 144.1334 - learning_rate: 5.0000e-04\n",
      "Epoch 177/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 95.0011 - mae: 92.8696 - val_loss: 145.8505 - val_mae: 143.7080 - learning_rate: 5.0000e-04\n",
      "Epoch 178/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 99.2376 - mae: 97.0859 - val_loss: 144.6300 - val_mae: 142.4599 - learning_rate: 5.0000e-04\n",
      "Epoch 179/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 97.5062 - mae: 95.3324 - val_loss: 144.7926 - val_mae: 142.6090 - learning_rate: 5.0000e-04\n",
      "Epoch 180/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 94.1030 - mae: 91.9086 - val_loss: 145.8831 - val_mae: 143.6733 - learning_rate: 5.0000e-04\n",
      "Epoch 181/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 95.5012 - mae: 93.2880 - val_loss: 144.2266 - val_mae: 142.0026 - learning_rate: 5.0000e-04\n",
      "Epoch 182/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 96.5192 - mae: 94.2843 - val_loss: 143.6345 - val_mae: 141.3853 - learning_rate: 5.0000e-04\n",
      "Epoch 183/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 95.1124 - mae: 92.8589 - val_loss: 143.1982 - val_mae: 140.9285 - learning_rate: 5.0000e-04\n",
      "Epoch 184/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 93.2734 - mae: 91.0000 - val_loss: 143.0704 - val_mae: 140.7800 - learning_rate: 5.0000e-04\n",
      "Epoch 185/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 93.6786 - mae: 91.3864 - val_loss: 142.7744 - val_mae: 140.4677 - learning_rate: 5.0000e-04\n",
      "Epoch 186/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 92.6198 - mae: 90.3063 - val_loss: 142.4061 - val_mae: 140.0797 - learning_rate: 5.0000e-04\n",
      "Epoch 187/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 92.5728 - mae: 90.2412 - val_loss: 143.4202 - val_mae: 141.0754 - learning_rate: 5.0000e-04\n",
      "Epoch 188/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 92.7170 - mae: 90.3596 - val_loss: 141.6977 - val_mae: 139.3257 - learning_rate: 5.0000e-04\n",
      "Epoch 189/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 92.3716 - mae: 89.9984 - val_loss: 141.6588 - val_mae: 139.2694 - learning_rate: 5.0000e-04\n",
      "Epoch 190/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 93.7404 - mae: 91.3484 - val_loss: 141.2676 - val_mae: 138.8599 - learning_rate: 5.0000e-04\n",
      "Epoch 191/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 91.5925 - mae: 89.1747 - val_loss: 140.9089 - val_mae: 138.4797 - learning_rate: 5.0000e-04\n",
      "Epoch 192/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 94.9385 - mae: 92.5053 - val_loss: 140.6375 - val_mae: 138.1838 - learning_rate: 5.0000e-04\n",
      "Epoch 193/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 92.2081 - mae: 89.7565 - val_loss: 142.2384 - val_mae: 139.7751 - learning_rate: 5.0000e-04\n",
      "Epoch 194/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 91.2554 - mae: 88.7819 - val_loss: 140.2200 - val_mae: 137.7326 - learning_rate: 5.0000e-04\n",
      "Epoch 195/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 91.8048 - mae: 89.3096 - val_loss: 141.7846 - val_mae: 139.2809 - learning_rate: 5.0000e-04\n",
      "Epoch 196/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 90.6784 - mae: 88.1669 - val_loss: 140.1954 - val_mae: 137.6689 - learning_rate: 5.0000e-04\n",
      "Epoch 197/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 92.2654 - mae: 89.7343 - val_loss: 139.6706 - val_mae: 137.1173 - learning_rate: 5.0000e-04\n",
      "Epoch 198/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 92.4772 - mae: 89.9224 - val_loss: 139.9973 - val_mae: 137.4263 - learning_rate: 5.0000e-04\n",
      "Epoch 199/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 90.7807 - mae: 88.2042 - val_loss: 140.0025 - val_mae: 137.4148 - learning_rate: 5.0000e-04\n",
      "Epoch 200/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 91.4523 - mae: 88.8601 - val_loss: 139.9643 - val_mae: 137.3466 - learning_rate: 5.0000e-04\n",
      "Epoch 201/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 90.7530 - mae: 88.1420 - val_loss: 138.7618 - val_mae: 136.1340 - learning_rate: 5.0000e-04\n",
      "Epoch 202/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 90.1475 - mae: 87.5141 - val_loss: 138.9974 - val_mae: 136.3396 - learning_rate: 5.0000e-04\n",
      "Epoch 203/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 88.9739 - mae: 86.3242 - val_loss: 140.7551 - val_mae: 138.0849 - learning_rate: 5.0000e-04\n",
      "Epoch 204/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 88.6826 - mae: 86.0115 - val_loss: 138.7454 - val_mae: 136.0556 - learning_rate: 5.0000e-04\n",
      "Epoch 205/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 87.7797 - mae: 85.0908 - val_loss: 138.4884 - val_mae: 135.7890 - learning_rate: 5.0000e-04\n",
      "Epoch 206/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 89.6247 - mae: 86.9193 - val_loss: 138.6738 - val_mae: 135.9563 - learning_rate: 5.0000e-04\n",
      "Epoch 207/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 88.9740 - mae: 86.2444 - val_loss: 138.5194 - val_mae: 135.7840 - learning_rate: 5.0000e-04\n",
      "Epoch 208/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 89.2657 - mae: 86.5191 - val_loss: 138.4073 - val_mae: 135.6458 - learning_rate: 5.0000e-04\n",
      "Epoch 209/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 90.7923 - mae: 88.0277 - val_loss: 137.8036 - val_mae: 135.0296 - learning_rate: 5.0000e-04\n",
      "Epoch 210/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 87.8943 - mae: 85.1118 - val_loss: 137.2232 - val_mae: 134.4214 - learning_rate: 5.0000e-04\n",
      "Epoch 211/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 85.5959 - mae: 82.7940 - val_loss: 136.9538 - val_mae: 134.1352 - learning_rate: 5.0000e-04\n",
      "Epoch 212/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 85.4845 - mae: 82.6654 - val_loss: 136.8165 - val_mae: 133.9788 - learning_rate: 5.0000e-04\n",
      "Epoch 213/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 87.4405 - mae: 84.5971 - val_loss: 137.3254 - val_mae: 134.4703 - learning_rate: 5.0000e-04\n",
      "Epoch 214/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 87.0941 - mae: 84.2355 - val_loss: 137.2880 - val_mae: 134.4180 - learning_rate: 5.0000e-04\n",
      "Epoch 215/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 88.1819 - mae: 85.3063 - val_loss: 136.5407 - val_mae: 133.6420 - learning_rate: 5.0000e-04\n",
      "Epoch 216/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 86.2042 - mae: 83.3065 - val_loss: 136.0040 - val_mae: 133.0888 - learning_rate: 5.0000e-04\n",
      "Epoch 217/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 87.8769 - mae: 84.9597 - val_loss: 135.7986 - val_mae: 132.8562 - learning_rate: 5.0000e-04\n",
      "Epoch 218/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 86.2881 - mae: 83.3522 - val_loss: 136.3752 - val_mae: 133.4100 - learning_rate: 5.0000e-04\n",
      "Epoch 219/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 85.2133 - mae: 82.2590 - val_loss: 136.7696 - val_mae: 133.8041 - learning_rate: 5.0000e-04\n",
      "Epoch 220/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 85.4137 - mae: 82.4399 - val_loss: 136.2270 - val_mae: 133.2303 - learning_rate: 5.0000e-04\n",
      "Epoch 221/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 85.4695 - mae: 82.4718 - val_loss: 135.3189 - val_mae: 132.3051 - learning_rate: 5.0000e-04\n",
      "Epoch 222/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 86.4573 - mae: 83.4432 - val_loss: 135.1596 - val_mae: 132.1220 - learning_rate: 5.0000e-04\n",
      "Epoch 223/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 82.5981 - mae: 79.5656 - val_loss: 135.6178 - val_mae: 132.5576 - learning_rate: 5.0000e-04\n",
      "Epoch 224/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 84.5999 - mae: 81.5504 - val_loss: 137.1474 - val_mae: 134.0872 - learning_rate: 5.0000e-04\n",
      "Epoch 225/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 85.3176 - mae: 82.2494 - val_loss: 137.6384 - val_mae: 134.5622 - learning_rate: 5.0000e-04\n",
      "Epoch 226/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 86.4162 - mae: 83.3327 - val_loss: 135.2554 - val_mae: 132.1614 - learning_rate: 5.0000e-04\n",
      "Epoch 227/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 82.1506 - mae: 79.0472 - val_loss: 135.1148 - val_mae: 132.0002 - learning_rate: 5.0000e-04\n",
      "Epoch 228/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 84.5571 - mae: 81.4368 - val_loss: 135.0288 - val_mae: 131.8998 - learning_rate: 5.0000e-04\n",
      "Epoch 229/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 86.0132 - mae: 82.8806 - val_loss: 134.9055 - val_mae: 131.7587 - learning_rate: 5.0000e-04\n",
      "Epoch 230/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 85.0159 - mae: 81.8644 - val_loss: 137.1990 - val_mae: 134.0341 - learning_rate: 5.0000e-04\n",
      "Epoch 231/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 84.7922 - mae: 81.6239 - val_loss: 136.7135 - val_mae: 133.5380 - learning_rate: 5.0000e-04\n",
      "Epoch 232/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 83.5461 - mae: 80.3627 - val_loss: 138.0703 - val_mae: 134.8773 - learning_rate: 5.0000e-04\n",
      "Epoch 233/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 83.6413 - mae: 80.4433 - val_loss: 135.0028 - val_mae: 131.7918 - learning_rate: 5.0000e-04\n",
      "Epoch 234/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 82.4775 - mae: 79.2596 - val_loss: 134.6377 - val_mae: 131.4092 - learning_rate: 5.0000e-04\n",
      "Epoch 235/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 82.1092 - mae: 78.8756 - val_loss: 134.3349 - val_mae: 131.0900 - learning_rate: 5.0000e-04\n",
      "Epoch 236/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80.5918 - mae: 77.3438 - val_loss: 134.2111 - val_mae: 130.9507 - learning_rate: 5.0000e-04\n",
      "Epoch 237/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80.8273 - mae: 77.5601 - val_loss: 134.2397 - val_mae: 130.9623 - learning_rate: 5.0000e-04\n",
      "Epoch 238/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 81.9373 - mae: 78.6528 - val_loss: 133.7456 - val_mae: 130.4452 - learning_rate: 5.0000e-04\n",
      "Epoch 239/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80.5926 - mae: 77.2857 - val_loss: 133.7593 - val_mae: 130.4467 - learning_rate: 5.0000e-04\n",
      "Epoch 240/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 81.7485 - mae: 78.4269 - val_loss: 133.9656 - val_mae: 130.6368 - learning_rate: 5.0000e-04\n",
      "Epoch 241/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 81.2637 - mae: 77.9258 - val_loss: 133.8016 - val_mae: 130.4450 - learning_rate: 5.0000e-04\n",
      "Epoch 242/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 79.6990 - mae: 76.3416 - val_loss: 134.4311 - val_mae: 131.0639 - learning_rate: 5.0000e-04\n",
      "Epoch 243/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 62.6988 - mae: 59.3300\n",
      "Epoch 243: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 82.2424 - mae: 78.8696 - val_loss: 134.2755 - val_mae: 130.8891 - learning_rate: 5.0000e-04\n",
      "Epoch 244/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.6156 - mae: 75.2251 - val_loss: 133.7531 - val_mae: 130.3541 - learning_rate: 2.5000e-04\n",
      "Epoch 245/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 82.0623 - mae: 78.6680 - val_loss: 134.4030 - val_mae: 131.0027 - learning_rate: 2.5000e-04\n",
      "Epoch 246/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 79.5789 - mae: 76.1711 - val_loss: 133.5398 - val_mae: 130.1310 - learning_rate: 2.5000e-04\n",
      "Epoch 247/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 81.2155 - mae: 77.8065 - val_loss: 134.2024 - val_mae: 130.7889 - learning_rate: 2.5000e-04\n",
      "Epoch 248/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 80.9940 - mae: 77.5743 - val_loss: 133.9034 - val_mae: 130.4685 - learning_rate: 2.5000e-04\n",
      "Epoch 249/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 80.6606 - mae: 77.2355 - val_loss: 134.0318 - val_mae: 130.5944 - learning_rate: 2.5000e-04\n",
      "Epoch 250/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.7258 - mae: 76.2915 - val_loss: 134.1674 - val_mae: 130.7229 - learning_rate: 2.5000e-04\n",
      "Epoch 251/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 62.1854 - mae: 58.7470\n",
      "Epoch 251: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 81.1619 - mae: 77.7137 - val_loss: 133.8913 - val_mae: 130.4394 - learning_rate: 2.5000e-04\n",
      "Epoch 252/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.8778 - mae: 76.4276 - val_loss: 134.9543 - val_mae: 131.4989 - learning_rate: 1.2500e-04\n",
      "Epoch 253/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 82.9530 - mae: 79.5005 - val_loss: 133.5139 - val_mae: 130.0599 - learning_rate: 1.2500e-04\n",
      "Epoch 254/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 79.5622 - mae: 76.1021 - val_loss: 133.1534 - val_mae: 129.6857 - learning_rate: 1.2500e-04\n",
      "Epoch 255/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 79.7866 - mae: 76.3261 - val_loss: 132.9512 - val_mae: 129.4768 - learning_rate: 1.2500e-04\n",
      "Epoch 256/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.4458 - mae: 75.9810 - val_loss: 133.3088 - val_mae: 129.8426 - learning_rate: 1.2500e-04\n",
      "Epoch 257/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.4993 - mae: 76.0243 - val_loss: 133.0281 - val_mae: 129.5563 - learning_rate: 1.2500e-04\n",
      "Epoch 258/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.8504 - mae: 76.3779 - val_loss: 132.9772 - val_mae: 129.4975 - learning_rate: 1.2500e-04\n",
      "Epoch 259/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.4514 - mae: 74.9713 - val_loss: 133.2374 - val_mae: 129.7596 - learning_rate: 1.2500e-04\n",
      "Epoch 260/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 58.8799 - mae: 55.3987\n",
      "Epoch 260: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.5917 - mae: 76.1053 - val_loss: 133.2443 - val_mae: 129.7624 - learning_rate: 1.2500e-04\n",
      "Epoch 261/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 81.6409 - mae: 78.1547 - val_loss: 133.3810 - val_mae: 129.8964 - learning_rate: 1.0000e-04\n",
      "Epoch 262/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.3308 - mae: 74.8380 - val_loss: 133.1941 - val_mae: 129.7053 - learning_rate: 1.0000e-04\n",
      "Epoch 263/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.9636 - mae: 76.4678 - val_loss: 132.9376 - val_mae: 129.4415 - learning_rate: 1.0000e-04\n",
      "Epoch 264/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 81.0460 - mae: 77.5515 - val_loss: 133.0309 - val_mae: 129.5309 - learning_rate: 1.0000e-04\n",
      "Epoch 265/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 80.5700 - mae: 77.0730 - val_loss: 133.2300 - val_mae: 129.7326 - learning_rate: 1.0000e-04\n",
      "Epoch 266/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.4249 - mae: 74.9228 - val_loss: 133.3689 - val_mae: 129.8691 - learning_rate: 1.0000e-04\n",
      "Epoch 267/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 78.6444 - mae: 75.1391 - val_loss: 133.1553 - val_mae: 129.6516 - learning_rate: 1.0000e-04\n",
      "Epoch 268/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.1085 - mae: 74.5983 - val_loss: 132.8850 - val_mae: 129.3727 - learning_rate: 1.0000e-04\n",
      "Epoch 269/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80.2891 - mae: 76.7786 - val_loss: 133.5755 - val_mae: 130.0603 - learning_rate: 1.0000e-04\n",
      "Epoch 270/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.2503 - mae: 75.7367 - val_loss: 133.3700 - val_mae: 129.8512 - learning_rate: 1.0000e-04\n",
      "Epoch 271/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 78.8644 - mae: 75.3489 - val_loss: 133.3857 - val_mae: 129.8714 - learning_rate: 1.0000e-04\n",
      "Epoch 272/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 79.5866 - mae: 76.0678 - val_loss: 134.5016 - val_mae: 130.9827 - learning_rate: 1.0000e-04\n",
      "Epoch 273/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 78.1267 - mae: 74.6030 - val_loss: 133.1031 - val_mae: 129.5766 - learning_rate: 1.0000e-04\n",
      "Epoch 274/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.8446 - mae: 74.3184 - val_loss: 133.0958 - val_mae: 129.5643 - learning_rate: 1.0000e-04\n",
      "Epoch 275/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.2325 - mae: 74.6994 - val_loss: 132.9420 - val_mae: 129.4120 - learning_rate: 1.0000e-04\n",
      "Epoch 276/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.2280 - mae: 74.6963 - val_loss: 132.9198 - val_mae: 129.3828 - learning_rate: 1.0000e-04\n",
      "Epoch 277/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 79.8534 - mae: 76.3218 - val_loss: 133.2392 - val_mae: 129.7083 - learning_rate: 1.0000e-04\n",
      "Epoch 278/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.8268 - mae: 75.2882 - val_loss: 133.2155 - val_mae: 129.6817 - learning_rate: 1.0000e-04\n",
      "Epoch 279/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 79.0039 - mae: 75.4642 - val_loss: 133.3251 - val_mae: 129.7887 - learning_rate: 1.0000e-04\n",
      "Epoch 280/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.7371 - mae: 75.1935 - val_loss: 133.1468 - val_mae: 129.6074 - learning_rate: 1.0000e-04\n",
      "Epoch 281/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 80.2664 - mae: 76.7223 - val_loss: 133.0375 - val_mae: 129.4888 - learning_rate: 1.0000e-04\n",
      "Epoch 282/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 78.7708 - mae: 75.2235 - val_loss: 133.0418 - val_mae: 129.4920 - learning_rate: 1.0000e-04\n",
      "Epoch 283/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.3025 - mae: 75.7545 - val_loss: 133.3176 - val_mae: 129.7663 - learning_rate: 1.0000e-04\n",
      "Epoch 284/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.7275 - mae: 75.1757 - val_loss: 132.8627 - val_mae: 129.3085 - learning_rate: 1.0000e-04\n",
      "Epoch 285/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.1624 - mae: 73.6035 - val_loss: 133.1865 - val_mae: 129.6257 - learning_rate: 1.0000e-04\n",
      "Epoch 286/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 79.3619 - mae: 75.8026 - val_loss: 132.7270 - val_mae: 129.1680 - learning_rate: 1.0000e-04\n",
      "Epoch 287/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.8154 - mae: 74.2535 - val_loss: 132.8871 - val_mae: 129.3205 - learning_rate: 1.0000e-04\n",
      "Epoch 288/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 77.5701 - mae: 74.0060 - val_loss: 133.1104 - val_mae: 129.5476 - learning_rate: 1.0000e-04\n",
      "Epoch 289/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 78.1198 - mae: 74.5497 - val_loss: 132.8815 - val_mae: 129.3150 - learning_rate: 1.0000e-04\n",
      "Epoch 290/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.7531 - mae: 75.1819 - val_loss: 133.0282 - val_mae: 129.4596 - learning_rate: 1.0000e-04\n",
      "Epoch 291/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 78.0825 - mae: 74.5081 - val_loss: 132.9848 - val_mae: 129.4133 - learning_rate: 1.0000e-04\n",
      "Epoch 292/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 78.6189 - mae: 75.0397 - val_loss: 132.9646 - val_mae: 129.3900 - learning_rate: 1.0000e-04\n",
      "Epoch 293/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 77.9535 - mae: 74.3738 - val_loss: 132.8763 - val_mae: 129.2985 - learning_rate: 1.0000e-04\n",
      "Epoch 294/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 77.4932 - mae: 73.9085 - val_loss: 132.7037 - val_mae: 129.1221 - learning_rate: 1.0000e-04\n",
      "Epoch 295/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 78.2919 - mae: 74.7029 - val_loss: 132.6206 - val_mae: 129.0341 - learning_rate: 1.0000e-04\n",
      "Epoch 296/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 76.7618 - mae: 73.1659 - val_loss: 132.5124 - val_mae: 128.9198 - learning_rate: 1.0000e-04\n",
      "Epoch 297/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 77.0907 - mae: 73.5010 - val_loss: 132.4594 - val_mae: 128.8657 - learning_rate: 1.0000e-04\n",
      "Epoch 298/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 79.2385 - mae: 75.6436 - val_loss: 132.9115 - val_mae: 129.3194 - learning_rate: 1.0000e-04\n",
      "Epoch 299/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 77.9161 - mae: 74.3208 - val_loss: 133.1302 - val_mae: 129.5346 - learning_rate: 1.0000e-04\n",
      "Epoch 300/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.0721 - mae: 75.4728 - val_loss: 132.4466 - val_mae: 128.8462 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 300.\n",
      "Evalutaing Wide_Network_L2 on Test Set...\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "results = {}\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 300\n",
    "PATIENCE = 20\n",
    "\n",
    "# Callbacks for training\n",
    "callbacks = [\n",
    "          EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True, verbose=1),\n",
    "          ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING TENSORFLOW MODEL TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for builder in model_builders:\n",
    "          # Build Model\n",
    "          model = builder(input_dim)\n",
    "          model_name = model.name\n",
    "          print(f\"\\nTraining {model_name}...\")\n",
    "          \n",
    "          # Compile\n",
    "          # RMSprop for the Regularized/Robust model for diversification\n",
    "          optimizer = 'rmsprop' if model_name == 'Regularized_DNN_Robust' else 'adam'\n",
    "          model.compile(optimizer=optimizer, loss=tf.keras.losses.Huber(), metrics=['mae'])\n",
    "          \n",
    "          # Train\n",
    "          history = model.fit(\n",
    "                    X_train, y_train,\n",
    "                    validation_split=0.2, # Use 20% of train data for validation during training\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1\n",
    "          )\n",
    "          \n",
    "          # Evaluate on Test Set\n",
    "          print(f\"Evalutaing {model_name} on Test Set...\")\n",
    "          y_pred = model.predict(X_test).flatten()\n",
    "          \n",
    "          # Calculate Metrics\n",
    "          mae = mean_absolute_error(y_test, y_pred)\n",
    "          mse = mean_squared_error(y_test, y_pred)\n",
    "          r2 = r2_score(y_test, y_pred)\n",
    "          \n",
    "          results[model_name] = {'MAE': mae, 'MSE': mse, 'R2': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8787a737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                       DEEP LEARNING MODEL COMPARISON\n",
      "================================================================================\n",
      "|                        |     MAE |       MSE |     R2 |\n",
      "|:-----------------------|--------:|----------:|-------:|\n",
      "| Wide_Network_L2        | 105.109 | 43356.828 |  0.083 |\n",
      "| Simple_DNN_3_Layers_L2 | 178.553 | 68857.250 | -0.456 |\n",
      "| Deep_DNN_6_Layers_L2   | 182.975 | 72140.412 | -0.525 |\n",
      "| Regularized_DNN_Robust | 205.250 | 87256.570 | -0.845 |\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display Results\n",
    "\n",
    "metrics_df = pd.DataFrame(results).T\n",
    "metrics_df = metrics_df.sort_values(by='R2', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                       DEEP LEARNING MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(metrics_df.to_markdown(floatfmt=\".3f\"))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efc2ef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rayquaza\\AppData\\Local\\Temp\\ipykernel_2060\\3900825063.py:11: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(ax=axes[0], x='Model', y='R2', data=plot_df.sort_values(by='R2', ascending=False), palette='viridis')\n",
      "C:\\Users\\Rayquaza\\AppData\\Local\\Temp\\ipykernel_2060\\3900825063.py:20: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(ax=axes[1], x='Model', y='MAE', data=plot_df.sort_values(by='MAE', ascending=True), palette='plasma')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization\n",
    "\n",
    "# Prepare data for plotting\n",
    "metrics_to_plot = ['R2', 'MAE']\n",
    "plot_df = metrics_df[metrics_to_plot].reset_index().rename(columns={'index': 'Model'})\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "fig.suptitle('TensorFlow Deep Learning Performance Comparison', fontsize=18)\n",
    "\n",
    "# Plot R2 Score\n",
    "sns.barplot(ax=axes[0], x='Model', y='R2', data=plot_df.sort_values(by='R2', ascending=False), palette='viridis')\n",
    "axes[0].set_title('R2 Score (Higher is Better)')\n",
    "axes[0].set_ylim(min(plot_df['R2'].min(), 0) * 1.1, max(plot_df['R2'].max(), 1.0) * 1.05)\n",
    "axes[0].set_ylabel('R2 Score')\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container, fmt='%.3f')\n",
    "\n",
    "# Plot MAE (Mean Absolute Error)\n",
    "sns.barplot(ax=axes[1], x='Model', y='MAE', data=plot_df.sort_values(by='MAE', ascending=True), palette='plasma')\n",
    "axes[1].set_title('Mean Absolute Error (Lower is Better)')\n",
    "axes[1].set_ylabel('Profit ($)')\n",
    "axes[1].tick_params(axis='x', rotation=15)\n",
    "for container in axes[1].containers:\n",
    "    axes[1].bar_label(container, fmt='%.2f')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bca4f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary ---\n",
      "The best performing DL architecture is Wide_Network_L2.\n",
      "R2: 0.08328874931020513, MAE: 105.10919912636282\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Summary ---\")\n",
    "best_model = metrics_df.index[0]\n",
    "best_r2 = metrics_df.iloc[0]['R2']\n",
    "best_mae = metrics_df.iloc[0]['MAE']\n",
    "\n",
    "print(f\"The best performing DL architecture is {best_model}.\")\n",
    "print(f\"R2: {best_r2}, MAE: {best_mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
