{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a794a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db9073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeds for repoducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6506194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "          df = pd.read_csv(\"ML-Dataset.csv\")\n",
    "except FileNotFoundError:\n",
    "          print(\"Error: 'ML-Dataset.csv' not found. Please ensure the file is in the correct path.\")\n",
    "          exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "448ba600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "      <th>CountryName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>WarehouseAddress</th>\n",
       "      <th>WarehouseName</th>\n",
       "      <th>EmployeeName</th>\n",
       "      <th>EmployeeEmail</th>\n",
       "      <th>EmployeePhone</th>\n",
       "      <th>...</th>\n",
       "      <th>CustomerName</th>\n",
       "      <th>CustomerAddress</th>\n",
       "      <th>CustomerCreditLimit</th>\n",
       "      <th>CustomerEmail</th>\n",
       "      <th>CustomerPhone</th>\n",
       "      <th>Status</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>OrderItemQuantity</th>\n",
       "      <th>PerUnitPrice</th>\n",
       "      <th>TotalItemQuantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>26192</td>\n",
       "      <td>2014 Jabberwocky Rd</td>\n",
       "      <td>Southlake Texas</td>\n",
       "      <td>Summer Payne</td>\n",
       "      <td>summer.payne@example.com</td>\n",
       "      <td>5151238181</td>\n",
       "      <td>...</td>\n",
       "      <td>Flor Stone</td>\n",
       "      <td>2904 S Salina St</td>\n",
       "      <td>5000</td>\n",
       "      <td>flor.stone@raytheon.com</td>\n",
       "      <td>13171234104</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>17-Nov-16</td>\n",
       "      <td>132</td>\n",
       "      <td>469.99</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>26192</td>\n",
       "      <td>2014 Jabberwocky Rd</td>\n",
       "      <td>Southlake Texas</td>\n",
       "      <td>Rose Stephens</td>\n",
       "      <td>rose.stephens@example.com</td>\n",
       "      <td>5151238080</td>\n",
       "      <td>...</td>\n",
       "      <td>Lavera Emerson</td>\n",
       "      <td>5344 Haverford Ave, Philadelphia</td>\n",
       "      <td>5000</td>\n",
       "      <td>lavera.emerson@plainsallamerican.com</td>\n",
       "      <td>13171234111</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>20-Feb-17</td>\n",
       "      <td>124</td>\n",
       "      <td>519.99</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>26192</td>\n",
       "      <td>2014 Jabberwocky Rd</td>\n",
       "      <td>Southlake Texas</td>\n",
       "      <td>Annabelle Dunn</td>\n",
       "      <td>annabelle.dunn@example.com</td>\n",
       "      <td>5151234444</td>\n",
       "      <td>...</td>\n",
       "      <td>Fern Head</td>\n",
       "      <td>1795 Wu Meng, Muang Chonburi</td>\n",
       "      <td>1200</td>\n",
       "      <td>fern.head@usfoods.com</td>\n",
       "      <td>18121234115</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>03-Jan-17</td>\n",
       "      <td>92</td>\n",
       "      <td>800.74</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>26192</td>\n",
       "      <td>2014 Jabberwocky Rd</td>\n",
       "      <td>Southlake Texas</td>\n",
       "      <td>Tommy Bailey</td>\n",
       "      <td>tommy.bailey@example.com</td>\n",
       "      <td>5151234567</td>\n",
       "      <td>...</td>\n",
       "      <td>Shyla Ortiz</td>\n",
       "      <td>Walpurgisstr 69, Munich</td>\n",
       "      <td>2400</td>\n",
       "      <td>shyla.ortiz@abbvie.com</td>\n",
       "      <td>13171234126</td>\n",
       "      <td>Pending</td>\n",
       "      <td>15-Oct-17</td>\n",
       "      <td>128</td>\n",
       "      <td>849.99</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>26192</td>\n",
       "      <td>2014 Jabberwocky Rd</td>\n",
       "      <td>Southlake Texas</td>\n",
       "      <td>Blake Cooper</td>\n",
       "      <td>blake.cooper@example.com</td>\n",
       "      <td>5151234569</td>\n",
       "      <td>...</td>\n",
       "      <td>Jeni Levy</td>\n",
       "      <td>Via Frenzy 6903, Roma</td>\n",
       "      <td>1200</td>\n",
       "      <td>jeni.levy@centene.com</td>\n",
       "      <td>18121214129</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>09-Apr-17</td>\n",
       "      <td>106</td>\n",
       "      <td>109.99</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>490231</td>\n",
       "      <td>1298 Vileparle (E)</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Veera Abdellah</td>\n",
       "      <td>VeeraAbdellah@gmail.com</td>\n",
       "      <td>8788092231</td>\n",
       "      <td>...</td>\n",
       "      <td>Vega Vincent</td>\n",
       "      <td>4284 Dorigo Ln</td>\n",
       "      <td>4900</td>\n",
       "      <td>VegaVincent@gmail.com</td>\n",
       "      <td>787879874</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>27-Sep-17</td>\n",
       "      <td>32</td>\n",
       "      <td>725.99</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>490231</td>\n",
       "      <td>1298 Vileparle (E)</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Vega Vincent</td>\n",
       "      <td>VegaVincent@gmail.com</td>\n",
       "      <td>6700989921</td>\n",
       "      <td>...</td>\n",
       "      <td>Villanueva Noah</td>\n",
       "      <td>6794 Lake Dr E</td>\n",
       "      <td>5000</td>\n",
       "      <td>VillanuevaNoah@gmail.com</td>\n",
       "      <td>785811219</td>\n",
       "      <td>Pending</td>\n",
       "      <td>16-Aug-16</td>\n",
       "      <td>66</td>\n",
       "      <td>798.26</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>490231</td>\n",
       "      <td>1298 Vileparle (E)</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Villanueva Noah</td>\n",
       "      <td>VillanuevaNoah@gmail.com</td>\n",
       "      <td>7890991231</td>\n",
       "      <td>...</td>\n",
       "      <td>Voldemort Lord</td>\n",
       "      <td>31 Douglas Blvd #950</td>\n",
       "      <td>4000</td>\n",
       "      <td>VoldemortLord@gmail.com</td>\n",
       "      <td>789243757</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>27-May-16</td>\n",
       "      <td>82</td>\n",
       "      <td>849.99</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>490231</td>\n",
       "      <td>1298 Vileparle (E)</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Zima Colleen</td>\n",
       "      <td>ZimaColleen@gmail.com</td>\n",
       "      <td>8690991436</td>\n",
       "      <td>...</td>\n",
       "      <td>Lucy Cechtelar</td>\n",
       "      <td>44 W 4th St</td>\n",
       "      <td>3000</td>\n",
       "      <td>LucyCechtelar@gmail.com</td>\n",
       "      <td>964940981</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>27-May-17</td>\n",
       "      <td>157</td>\n",
       "      <td>821.99</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>490231</td>\n",
       "      <td>1298 Vileparle (E)</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Volk Colleen</td>\n",
       "      <td>VolkCollen@gmail.com</td>\n",
       "      <td>9426826971</td>\n",
       "      <td>...</td>\n",
       "      <td>John Snow</td>\n",
       "      <td>11279 Loytan St</td>\n",
       "      <td>2000</td>\n",
       "      <td>JohnSnow@gmail.com</td>\n",
       "      <td>567897474</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>27-May-17</td>\n",
       "      <td>32</td>\n",
       "      <td>579.59</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegionName               CountryName        State       City  \\\n",
       "0    South America  United States of America        Texas  Southlake   \n",
       "1    South America  United States of America        Texas  Southlake   \n",
       "2    South America  United States of America        Texas  Southlake   \n",
       "3    South America  United States of America        Texas  Southlake   \n",
       "4    South America  United States of America        Texas  Southlake   \n",
       "..             ...                       ...          ...        ...   \n",
       "395           Asia                     India  Maharashtra     Bombay   \n",
       "396           Asia                     India  Maharashtra     Bombay   \n",
       "397           Asia                     India  Maharashtra     Bombay   \n",
       "398           Asia                     India  Maharashtra     Bombay   \n",
       "399           Asia                     India  Maharashtra     Bombay   \n",
       "\n",
       "    PostalCode     WarehouseAddress    WarehouseName     EmployeeName  \\\n",
       "0        26192  2014 Jabberwocky Rd  Southlake Texas     Summer Payne   \n",
       "1        26192  2014 Jabberwocky Rd  Southlake Texas    Rose Stephens   \n",
       "2        26192  2014 Jabberwocky Rd  Southlake Texas   Annabelle Dunn   \n",
       "3        26192  2014 Jabberwocky Rd  Southlake Texas     Tommy Bailey   \n",
       "4        26192  2014 Jabberwocky Rd  Southlake Texas     Blake Cooper   \n",
       "..         ...                  ...              ...              ...   \n",
       "395     490231   1298 Vileparle (E)           Bombay   Veera Abdellah   \n",
       "396     490231   1298 Vileparle (E)           Bombay     Vega Vincent   \n",
       "397     490231   1298 Vileparle (E)           Bombay  Villanueva Noah   \n",
       "398     490231   1298 Vileparle (E)           Bombay     Zima Colleen   \n",
       "399     490231   1298 Vileparle (E)           Bombay     Volk Colleen   \n",
       "\n",
       "                  EmployeeEmail  EmployeePhone  ...     CustomerName  \\\n",
       "0      summer.payne@example.com     5151238181  ...       Flor Stone   \n",
       "1     rose.stephens@example.com     5151238080  ...   Lavera Emerson   \n",
       "2    annabelle.dunn@example.com     5151234444  ...        Fern Head   \n",
       "3      tommy.bailey@example.com     5151234567  ...      Shyla Ortiz   \n",
       "4      blake.cooper@example.com     5151234569  ...        Jeni Levy   \n",
       "..                          ...            ...  ...              ...   \n",
       "395     VeeraAbdellah@gmail.com     8788092231  ...     Vega Vincent   \n",
       "396       VegaVincent@gmail.com     6700989921  ...  Villanueva Noah   \n",
       "397    VillanuevaNoah@gmail.com     7890991231  ...   Voldemort Lord   \n",
       "398       ZimaColleen@gmail.com     8690991436  ...   Lucy Cechtelar   \n",
       "399        VolkCollen@gmail.com     9426826971  ...        John Snow   \n",
       "\n",
       "                      CustomerAddress CustomerCreditLimit  \\\n",
       "0                    2904 S Salina St                5000   \n",
       "1    5344 Haverford Ave, Philadelphia                5000   \n",
       "2        1795 Wu Meng, Muang Chonburi                1200   \n",
       "3             Walpurgisstr 69, Munich                2400   \n",
       "4               Via Frenzy 6903, Roma                1200   \n",
       "..                                ...                 ...   \n",
       "395                    4284 Dorigo Ln                4900   \n",
       "396                    6794 Lake Dr E                5000   \n",
       "397              31 Douglas Blvd #950                4000   \n",
       "398                       44 W 4th St                3000   \n",
       "399                   11279 Loytan St                2000   \n",
       "\n",
       "                            CustomerEmail CustomerPhone    Status  OrderDate  \\\n",
       "0                 flor.stone@raytheon.com   13171234104   Shipped  17-Nov-16   \n",
       "1    lavera.emerson@plainsallamerican.com   13171234111   Shipped  20-Feb-17   \n",
       "2                   fern.head@usfoods.com   18121234115  Canceled  03-Jan-17   \n",
       "3                  shyla.ortiz@abbvie.com   13171234126   Pending  15-Oct-17   \n",
       "4                   jeni.levy@centene.com   18121214129   Shipped  09-Apr-17   \n",
       "..                                    ...           ...       ...        ...   \n",
       "395                 VegaVincent@gmail.com     787879874   Shipped  27-Sep-17   \n",
       "396              VillanuevaNoah@gmail.com     785811219   Pending  16-Aug-16   \n",
       "397               VoldemortLord@gmail.com     789243757  Canceled  27-May-16   \n",
       "398               LucyCechtelar@gmail.com     964940981   Shipped  27-May-17   \n",
       "399                    JohnSnow@gmail.com     567897474  Canceled  27-May-17   \n",
       "\n",
       "     OrderItemQuantity PerUnitPrice TotalItemQuantity  \n",
       "0                  132       469.99               122  \n",
       "1                  124       519.99               123  \n",
       "2                   92       800.74               123  \n",
       "3                  128       849.99               124  \n",
       "4                  106       109.99               125  \n",
       "..                 ...          ...               ...  \n",
       "395                 32       725.99               107  \n",
       "396                 66       798.26               118  \n",
       "397                 82       849.99               118  \n",
       "398                157       821.99                95  \n",
       "399                 32       579.59                92  \n",
       "\n",
       "[400 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5c8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'Profit'\n",
    "y = df[TARGET_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d54a5832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      542.95\n",
       "1      448.71\n",
       "2      625.54\n",
       "3      410.59\n",
       "4      489.58\n",
       "        ...  \n",
       "395    185.63\n",
       "396    168.84\n",
       "397    121.04\n",
       "398    147.64\n",
       "399     96.81\n",
       "Name: Profit, Length: 400, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31328771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection and Data Leakage Mitigation\n",
    "COLUMNS_TO_DROP = [\n",
    "    'CustomerName', 'CustomerAddress', 'CustomerEmail', 'CustomerPhone',\n",
    "    'EmployeeName', 'EmployeeEmail', 'EmployeePhone', 'EmployeeHireDate',\n",
    "    'WarehouseAddress', 'WarehouseName', 'PostalCode',\n",
    "    'ProductStandardCost', 'ProductListPrice' # Data Leakage\n",
    "]\n",
    "\n",
    "X = df.drop(COLUMNS_TO_DROP + [TARGET_COLUMN], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ebaba9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "      <th>CountryName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>EmployeeJobTitle</th>\n",
       "      <th>CategoryName</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>ProductDescription</th>\n",
       "      <th>CustomerCreditLimit</th>\n",
       "      <th>Status</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>OrderItemQuantity</th>\n",
       "      <th>PerUnitPrice</th>\n",
       "      <th>TotalItemQuantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Public Accountant</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2699 V3 (OEM/Tray)</td>\n",
       "      <td>Speed:2.3GHz,Cores:18,TDP:145W</td>\n",
       "      <td>5000</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>17-Nov-16</td>\n",
       "      <td>132</td>\n",
       "      <td>469.99</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2697 V3</td>\n",
       "      <td>Speed:2.6GHz,Cores:14</td>\n",
       "      <td>5000</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>20-Feb-17</td>\n",
       "      <td>124</td>\n",
       "      <td>519.99</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Administration Assistant</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2698 V3 (OEM/Tray)</td>\n",
       "      <td>Speed:2.3GHz</td>\n",
       "      <td>1200</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>03-Jan-17</td>\n",
       "      <td>92</td>\n",
       "      <td>800.74</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>President</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2697 V4</td>\n",
       "      <td>Cores:18,TDP:145W</td>\n",
       "      <td>2400</td>\n",
       "      <td>Pending</td>\n",
       "      <td>15-Oct-17</td>\n",
       "      <td>128</td>\n",
       "      <td>849.99</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Administration Vice President</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2685 V3 (OEM/Tray)</td>\n",
       "      <td>Speed:2.6GHz,Cores:12</td>\n",
       "      <td>1200</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>09-Apr-17</td>\n",
       "      <td>106</td>\n",
       "      <td>109.99</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Clerk</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>MSI GTX 1080 TI LIGHTNING Z</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>4900</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>27-Sep-17</td>\n",
       "      <td>32</td>\n",
       "      <td>725.99</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>Asus ROG-POSEIDON-GTX1080TI-P11G-GAMING</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>5000</td>\n",
       "      <td>Pending</td>\n",
       "      <td>16-Aug-16</td>\n",
       "      <td>66</td>\n",
       "      <td>798.26</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>MSI GTX 1080 TI LIGHTNING X</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>4000</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>27-May-16</td>\n",
       "      <td>82</td>\n",
       "      <td>849.99</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>Zotac ZT-P10810A-10P</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>3000</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>27-May-17</td>\n",
       "      <td>157</td>\n",
       "      <td>821.99</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>MSI GAMING</td>\n",
       "      <td>Chipset:GeForce GTX 780 Ti</td>\n",
       "      <td>2000</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>27-May-17</td>\n",
       "      <td>32</td>\n",
       "      <td>579.59</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegionName               CountryName        State       City  \\\n",
       "0    South America  United States of America        Texas  Southlake   \n",
       "1    South America  United States of America        Texas  Southlake   \n",
       "2    South America  United States of America        Texas  Southlake   \n",
       "3    South America  United States of America        Texas  Southlake   \n",
       "4    South America  United States of America        Texas  Southlake   \n",
       "..             ...                       ...          ...        ...   \n",
       "395           Asia                     India  Maharashtra     Bombay   \n",
       "396           Asia                     India  Maharashtra     Bombay   \n",
       "397           Asia                     India  Maharashtra     Bombay   \n",
       "398           Asia                     India  Maharashtra     Bombay   \n",
       "399           Asia                     India  Maharashtra     Bombay   \n",
       "\n",
       "                  EmployeeJobTitle CategoryName  \\\n",
       "0                Public Accountant          CPU   \n",
       "1               Accounting Manager          CPU   \n",
       "2         Administration Assistant          CPU   \n",
       "3                        President          CPU   \n",
       "4    Administration Vice President          CPU   \n",
       "..                             ...          ...   \n",
       "395                    Stock Clerk   Video Card   \n",
       "396                  Stock Manager   Video Card   \n",
       "397                  Stock Manager   Video Card   \n",
       "398                  Stock Manager   Video Card   \n",
       "399                  Stock Manager   Video Card   \n",
       "\n",
       "                                 ProductName              ProductDescription  \\\n",
       "0           Intel Xeon E5-2699 V3 (OEM/Tray)  Speed:2.3GHz,Cores:18,TDP:145W   \n",
       "1                      Intel Xeon E5-2697 V3           Speed:2.6GHz,Cores:14   \n",
       "2           Intel Xeon E5-2698 V3 (OEM/Tray)                    Speed:2.3GHz   \n",
       "3                      Intel Xeon E5-2697 V4               Cores:18,TDP:145W   \n",
       "4           Intel Xeon E5-2685 V3 (OEM/Tray)           Speed:2.6GHz,Cores:12   \n",
       "..                                       ...                             ...   \n",
       "395              MSI GTX 1080 TI LIGHTNING Z     Chipset:GeForce GTX 1080 Ti   \n",
       "396  Asus ROG-POSEIDON-GTX1080TI-P11G-GAMING     Chipset:GeForce GTX 1080 Ti   \n",
       "397              MSI GTX 1080 TI LIGHTNING X     Chipset:GeForce GTX 1080 Ti   \n",
       "398                     Zotac ZT-P10810A-10P     Chipset:GeForce GTX 1080 Ti   \n",
       "399                               MSI GAMING      Chipset:GeForce GTX 780 Ti   \n",
       "\n",
       "     CustomerCreditLimit    Status  OrderDate  OrderItemQuantity  \\\n",
       "0                   5000   Shipped  17-Nov-16                132   \n",
       "1                   5000   Shipped  20-Feb-17                124   \n",
       "2                   1200  Canceled  03-Jan-17                 92   \n",
       "3                   2400   Pending  15-Oct-17                128   \n",
       "4                   1200   Shipped  09-Apr-17                106   \n",
       "..                   ...       ...        ...                ...   \n",
       "395                 4900   Shipped  27-Sep-17                 32   \n",
       "396                 5000   Pending  16-Aug-16                 66   \n",
       "397                 4000  Canceled  27-May-16                 82   \n",
       "398                 3000   Shipped  27-May-17                157   \n",
       "399                 2000  Canceled  27-May-17                 32   \n",
       "\n",
       "     PerUnitPrice  TotalItemQuantity  \n",
       "0          469.99                122  \n",
       "1          519.99                123  \n",
       "2          800.74                123  \n",
       "3          849.99                124  \n",
       "4          109.99                125  \n",
       "..            ...                ...  \n",
       "395        725.99                107  \n",
       "396        798.26                118  \n",
       "397        849.99                118  \n",
       "398        821.99                 95  \n",
       "399        579.59                 92  \n",
       "\n",
       "[400 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4788b8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (400, 28)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c372a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering (Temporal Data)\n",
    "# Convert OrderDate to datetime and extract useful features\n",
    "X['OrderDate'] = pd.to_datetime(X['OrderDate'], format='%d-%b-%y')\n",
    "X['Order_Month'] = X['OrderDate'].dt.month\n",
    "X['Order_Year'] = X['OrderDate'].dt.year\n",
    "X['Order_Weekday'] = X['OrderDate'].dt.dayofweek\n",
    "\n",
    "X = X.drop('OrderDate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0a3beb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "      <th>CountryName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>EmployeeJobTitle</th>\n",
       "      <th>CategoryName</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>ProductDescription</th>\n",
       "      <th>CustomerCreditLimit</th>\n",
       "      <th>Status</th>\n",
       "      <th>OrderItemQuantity</th>\n",
       "      <th>PerUnitPrice</th>\n",
       "      <th>TotalItemQuantity</th>\n",
       "      <th>Order_Month</th>\n",
       "      <th>Order_Year</th>\n",
       "      <th>Order_Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Public Accountant</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2699 V3 (OEM/Tray)</td>\n",
       "      <td>Speed:2.3GHz,Cores:18,TDP:145W</td>\n",
       "      <td>5000</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>132</td>\n",
       "      <td>469.99</td>\n",
       "      <td>122</td>\n",
       "      <td>11</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2697 V3</td>\n",
       "      <td>Speed:2.6GHz,Cores:14</td>\n",
       "      <td>5000</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>124</td>\n",
       "      <td>519.99</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Administration Assistant</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2698 V3 (OEM/Tray)</td>\n",
       "      <td>Speed:2.3GHz</td>\n",
       "      <td>1200</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>92</td>\n",
       "      <td>800.74</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>President</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2697 V4</td>\n",
       "      <td>Cores:18,TDP:145W</td>\n",
       "      <td>2400</td>\n",
       "      <td>Pending</td>\n",
       "      <td>128</td>\n",
       "      <td>849.99</td>\n",
       "      <td>124</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Southlake</td>\n",
       "      <td>Administration Vice President</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Intel Xeon E5-2685 V3 (OEM/Tray)</td>\n",
       "      <td>Speed:2.6GHz,Cores:12</td>\n",
       "      <td>1200</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>106</td>\n",
       "      <td>109.99</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Clerk</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>MSI GTX 1080 TI LIGHTNING Z</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>4900</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>32</td>\n",
       "      <td>725.99</td>\n",
       "      <td>107</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>Asus ROG-POSEIDON-GTX1080TI-P11G-GAMING</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>5000</td>\n",
       "      <td>Pending</td>\n",
       "      <td>66</td>\n",
       "      <td>798.26</td>\n",
       "      <td>118</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>MSI GTX 1080 TI LIGHTNING X</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>4000</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>82</td>\n",
       "      <td>849.99</td>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>Zotac ZT-P10810A-10P</td>\n",
       "      <td>Chipset:GeForce GTX 1080 Ti</td>\n",
       "      <td>3000</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>157</td>\n",
       "      <td>821.99</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Asia</td>\n",
       "      <td>India</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>Stock Manager</td>\n",
       "      <td>Video Card</td>\n",
       "      <td>MSI GAMING</td>\n",
       "      <td>Chipset:GeForce GTX 780 Ti</td>\n",
       "      <td>2000</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>32</td>\n",
       "      <td>579.59</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegionName               CountryName        State       City  \\\n",
       "0    South America  United States of America        Texas  Southlake   \n",
       "1    South America  United States of America        Texas  Southlake   \n",
       "2    South America  United States of America        Texas  Southlake   \n",
       "3    South America  United States of America        Texas  Southlake   \n",
       "4    South America  United States of America        Texas  Southlake   \n",
       "..             ...                       ...          ...        ...   \n",
       "395           Asia                     India  Maharashtra     Bombay   \n",
       "396           Asia                     India  Maharashtra     Bombay   \n",
       "397           Asia                     India  Maharashtra     Bombay   \n",
       "398           Asia                     India  Maharashtra     Bombay   \n",
       "399           Asia                     India  Maharashtra     Bombay   \n",
       "\n",
       "                  EmployeeJobTitle CategoryName  \\\n",
       "0                Public Accountant          CPU   \n",
       "1               Accounting Manager          CPU   \n",
       "2         Administration Assistant          CPU   \n",
       "3                        President          CPU   \n",
       "4    Administration Vice President          CPU   \n",
       "..                             ...          ...   \n",
       "395                    Stock Clerk   Video Card   \n",
       "396                  Stock Manager   Video Card   \n",
       "397                  Stock Manager   Video Card   \n",
       "398                  Stock Manager   Video Card   \n",
       "399                  Stock Manager   Video Card   \n",
       "\n",
       "                                 ProductName              ProductDescription  \\\n",
       "0           Intel Xeon E5-2699 V3 (OEM/Tray)  Speed:2.3GHz,Cores:18,TDP:145W   \n",
       "1                      Intel Xeon E5-2697 V3           Speed:2.6GHz,Cores:14   \n",
       "2           Intel Xeon E5-2698 V3 (OEM/Tray)                    Speed:2.3GHz   \n",
       "3                      Intel Xeon E5-2697 V4               Cores:18,TDP:145W   \n",
       "4           Intel Xeon E5-2685 V3 (OEM/Tray)           Speed:2.6GHz,Cores:12   \n",
       "..                                       ...                             ...   \n",
       "395              MSI GTX 1080 TI LIGHTNING Z     Chipset:GeForce GTX 1080 Ti   \n",
       "396  Asus ROG-POSEIDON-GTX1080TI-P11G-GAMING     Chipset:GeForce GTX 1080 Ti   \n",
       "397              MSI GTX 1080 TI LIGHTNING X     Chipset:GeForce GTX 1080 Ti   \n",
       "398                     Zotac ZT-P10810A-10P     Chipset:GeForce GTX 1080 Ti   \n",
       "399                               MSI GAMING      Chipset:GeForce GTX 780 Ti   \n",
       "\n",
       "     CustomerCreditLimit    Status  OrderItemQuantity  PerUnitPrice  \\\n",
       "0                   5000   Shipped                132        469.99   \n",
       "1                   5000   Shipped                124        519.99   \n",
       "2                   1200  Canceled                 92        800.74   \n",
       "3                   2400   Pending                128        849.99   \n",
       "4                   1200   Shipped                106        109.99   \n",
       "..                   ...       ...                ...           ...   \n",
       "395                 4900   Shipped                 32        725.99   \n",
       "396                 5000   Pending                 66        798.26   \n",
       "397                 4000  Canceled                 82        849.99   \n",
       "398                 3000   Shipped                157        821.99   \n",
       "399                 2000  Canceled                 32        579.59   \n",
       "\n",
       "     TotalItemQuantity  Order_Month  Order_Year  Order_Weekday  \n",
       "0                  122           11        2016              3  \n",
       "1                  123            2        2017              0  \n",
       "2                  123            1        2017              1  \n",
       "3                  124           10        2017              6  \n",
       "4                  125            4        2017              6  \n",
       "..                 ...          ...         ...            ...  \n",
       "395                107            9        2017              2  \n",
       "396                118            8        2016              1  \n",
       "397                118            5        2016              4  \n",
       "398                 95            5        2017              5  \n",
       "399                 92            5        2017              5  \n",
       "\n",
       "[400 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "735ffd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "NUMERICAL_FEATURES = ['CustomerCreditLimit', 'OrderItemQuantity', 'TotalItemQuantity', 'Order_Month', 'Order_Year', 'Order_Weekday']\n",
    "CATEGORICAL_FEATURES = X.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0a1d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d02ed8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "          transformers=[\n",
    "                    ('num', StandardScaler(), NUMERICAL_FEATURES),\n",
    "                    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), CATEGORICAL_FEATURES)\n",
    "          ],\n",
    "          remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71200e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "Processed feature count (Input Dimension): 498\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing data...\")\n",
    "X_train = preprocessor.fit_transform(X_train_raw)\n",
    "X_test = preprocessor.transform(X_test_raw)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "print(f\"Processed feature count (Input Dimension): {input_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa61dd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.93470588e-01,  1.20495243e+00, -2.06006865e-02, ...,\n",
       "         1.00000000e+00,  0.00000000e+00,  8.49990000e+02],\n",
       "       [-8.99981044e-01, -2.74234458e-01, -6.56500237e-02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  8.99990000e+02],\n",
       "       [-5.78377623e-01, -3.34609433e-01,  1.07559985e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  6.68900000e+01],\n",
       "       ...,\n",
       "       [-9.64301728e-01,  1.11438997e+00,  7.90287383e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.89999000e+03],\n",
       "       [ 7.08036062e-01, -3.34609433e-01,  1.31586298e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.46996000e+03],\n",
       "       [ 1.93470588e-01, -7.57234259e-01, -1.77752484e+00, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.46996000e+03]],\n",
       "      shape=(320, 498))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4feec180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15726378e+00, -1.66285889e+00, -4.41061167e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.13990000e+02],\n",
       "       [ 1.29149904e-01,  5.40827707e-01,  8.65369611e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.95720000e+02],\n",
       "       [ 2.57791272e-01, -1.42135899e+00,  8.65369611e-01, ...,\n",
       "         1.00000000e+00,  0.00000000e+00,  5.73990000e+02],\n",
       "       ...,\n",
       "       [-1.15726378e+00,  7.21952633e-01,  1.27081365e+00, ...,\n",
       "         1.00000000e+00,  0.00000000e+00,  6.44000000e+02],\n",
       "       [-1.09294310e+00,  1.44645234e+00, -2.75880264e-01, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  4.39900000e+01],\n",
       "       [-3.85415570e-01,  9.03077559e-01,  8.95402503e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.49900000e+01]],\n",
       "      shape=(80, 498))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45e5b9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      410.59\n",
       "18     526.88\n",
       "202    118.71\n",
       "250    346.35\n",
       "274     14.81\n",
       "        ...  \n",
       "71     519.86\n",
       "106    218.37\n",
       "270      0.00\n",
       "348      0.00\n",
       "102    226.48\n",
       "Name: Profit, Length: 320, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac1aef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Deep Learning Architectures (With L2 Regularization)\n",
    "L2_REG = 0.001 # Define L2 regularization strength\n",
    "\n",
    "def build_simple_dnn(input_dim):\n",
    "          \"\"\"A baseline, shallow neural network with L2 regularization.\"\"\"\n",
    "          model = Sequential([\n",
    "                    Input(shape=(input_dim,)),\n",
    "                    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(1, activation='linear') # Linear activation for regression\n",
    "          ], name=\"Simple_DNN_3_Layers_L2\")\n",
    "          return model\n",
    "\n",
    "def build_deep_dnn(input_dim):\n",
    "          \"\"\"A deeper network with L2 regulariation and increased capacity (6 layers).\"\"\"\n",
    "          model = Sequential([\n",
    "                    Input(shape=(input_dim,)),\n",
    "                    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(1, activation='linear')\n",
    "          ], name=\"Deep_DNN_6_Layers_L2\")\n",
    "          return model\n",
    "\n",
    "def build_regularized_dnn(input_dim):\n",
    "          \"\"\"Deep network with Dropout, BatchNormalization and L2 regularization.\"\"\"\n",
    "          model = Sequential([\n",
    "                    Input(shape=(input_dim,)),\n",
    "                    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.3),\n",
    "                    \n",
    "                    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.3),\n",
    "                    \n",
    "                    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dense(1, activation='linear')\n",
    "          ], name=\"Regularized_DNN_Robust\")\n",
    "          return model\n",
    "\n",
    "def build_wide_network(input_dim):\n",
    "          \"\"\"A very wide network with fewer layers and L2 regularization.\"\"\"\n",
    "          model = Sequential([\n",
    "                    Input(shape=(input_dim,)),\n",
    "                    Dense(512, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "                    Dropout(0.2),\n",
    "                    Dense(1, activation='linear')\n",
    "          ], name=\"Wide_Network_L2\")\n",
    "          return model\n",
    "\n",
    "# Dictionary of model builders\n",
    "model_builders = [\n",
    "          build_simple_dnn,\n",
    "          build_deep_dnn,\n",
    "          build_regularized_dnn,\n",
    "          build_wide_network\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37956e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING TENSORFLOW MODEL TRAINING\n",
      "================================================================================\n",
      "\n",
      "Training Simple_DNN_3_Layers_L2...\n",
      "Epoch 1/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 147.6548 - mae: 147.9987 - val_loss: 197.8736 - val_mae: 198.2274 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.9962 - mae: 147.3515 - val_loss: 197.4813 - val_mae: 197.8440 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 146.5693 - mae: 146.9349 - val_loss: 197.7719 - val_mae: 198.1427 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.2126 - mae: 146.5863 - val_loss: 198.5029 - val_mae: 198.8810 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 146.0568 - mae: 146.4364 - val_loss: 199.2116 - val_mae: 199.5963 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 146.0472 - mae: 146.4322 - val_loss: 199.5485 - val_mae: 199.9390 - learning_rate: 0.0010\n",
      "Epoch 7/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 132.0674 - mae: 132.4579\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.0750 - mae: 146.4664 - val_loss: 199.3423 - val_mae: 199.7381 - learning_rate: 0.0010\n",
      "Epoch 8/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.9599 - mae: 146.3547 - val_loss: 199.0764 - val_mae: 199.4745 - learning_rate: 5.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.9061 - mae: 146.3032 - val_loss: 198.7972 - val_mae: 199.1974 - learning_rate: 5.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.8517 - mae: 146.2527 - val_loss: 198.6101 - val_mae: 199.0124 - learning_rate: 5.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.7984 - mae: 146.2007 - val_loss: 198.5285 - val_mae: 198.9326 - learning_rate: 5.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 131.6286 - mae: 132.0327\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.7417 - mae: 146.1454 - val_loss: 198.5473 - val_mae: 198.9531 - learning_rate: 5.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.6933 - mae: 146.0990 - val_loss: 198.5746 - val_mae: 198.9813 - learning_rate: 2.5000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.6712 - mae: 146.0782 - val_loss: 198.5883 - val_mae: 198.9957 - learning_rate: 2.5000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.6456 - mae: 146.0533 - val_loss: 198.5612 - val_mae: 198.9693 - learning_rate: 2.5000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.6152 - mae: 146.0236 - val_loss: 198.5594 - val_mae: 198.9682 - learning_rate: 2.5000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 131.4762 - mae: 131.8850\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.5909 - mae: 146.0000 - val_loss: 198.5580 - val_mae: 198.9675 - learning_rate: 2.5000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.5648 - mae: 145.9743 - val_loss: 198.5570 - val_mae: 198.9668 - learning_rate: 1.2500e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 145.5525 - mae: 145.9624 - val_loss: 198.5553 - val_mae: 198.9654 - learning_rate: 1.2500e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.5402 - mae: 145.9504 - val_loss: 198.5528 - val_mae: 198.9632 - learning_rate: 1.2500e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.5277 - mae: 145.9382 - val_loss: 198.5500 - val_mae: 198.9607 - learning_rate: 1.2500e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 131.3981 - mae: 131.8089\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 145.5151 - mae: 145.9259 - val_loss: 198.5476 - val_mae: 198.9586 - learning_rate: 1.2500e-04\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Evalutaing Simple_DNN_3_Layers_L2 on Test Set...\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "Training Deep_DNN_6_Layers_L2...\n",
      "Epoch 1/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 152.6404 - mae: 152.4607 - val_loss: 197.6714 - val_mae: 197.5253 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 147.0166 - mae: 146.8889 - val_loss: 200.6729 - val_mae: 200.5750 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 147.7216 - mae: 147.6368 - val_loss: 200.7117 - val_mae: 200.6574 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 147.0991 - mae: 147.0592 - val_loss: 198.3722 - val_mae: 198.3572 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 132.3749 - mae: 132.3599\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 147.0147 - mae: 147.0123 - val_loss: 197.7378 - val_mae: 197.7581 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.6729 - mae: 146.6990 - val_loss: 197.8271 - val_mae: 197.8634 - learning_rate: 5.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.3952 - mae: 146.4365 - val_loss: 198.2426 - val_mae: 198.2941 - learning_rate: 5.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.2643 - mae: 146.3211 - val_loss: 198.8589 - val_mae: 198.9245 - learning_rate: 5.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 146.1765 - mae: 146.2472 - val_loss: 199.2973 - val_mae: 199.3762 - learning_rate: 5.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 132.1265 - mae: 132.2006\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 146.1557 - mae: 146.2382 - val_loss: 199.4674 - val_mae: 199.5588 - learning_rate: 5.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.1350 - mae: 146.2272 - val_loss: 199.3418 - val_mae: 199.4391 - learning_rate: 2.5000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.0981 - mae: 146.1962 - val_loss: 199.1213 - val_mae: 199.2242 - learning_rate: 2.5000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.0555 - mae: 146.1602 - val_loss: 198.9249 - val_mae: 199.0333 - learning_rate: 2.5000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 146.0102 - mae: 146.1206 - val_loss: 198.7847 - val_mae: 198.8984 - learning_rate: 2.5000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 131.8371 - mae: 131.9508\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 145.9625 - mae: 146.0763 - val_loss: 198.7144 - val_mae: 198.8332 - learning_rate: 2.5000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.9071 - mae: 146.0251 - val_loss: 198.7202 - val_mae: 198.8414 - learning_rate: 1.2500e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.8826 - mae: 146.0042 - val_loss: 198.7426 - val_mae: 198.8663 - learning_rate: 1.2500e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 145.8625 - mae: 145.9871 - val_loss: 198.7560 - val_mae: 198.8820 - learning_rate: 1.2500e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145.8420 - mae: 145.9689 - val_loss: 198.7552 - val_mae: 198.8836 - learning_rate: 1.2500e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 131.7021 - mae: 131.8305\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 145.8204 - mae: 145.9496 - val_loss: 198.7453 - val_mae: 198.8760 - learning_rate: 1.2500e-04\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Evalutaing Deep_DNN_6_Layers_L2 on Test Set...\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "Training Regularized_DNN_Robust...\n",
      "Epoch 1/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 173.7078 - mae: 173.6091 - val_loss: 220.9071 - val_mae: 220.8262 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 172.1479 - mae: 172.0793 - val_loss: 219.9811 - val_mae: 219.9158 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 170.8621 - mae: 170.8102 - val_loss: 218.9933 - val_mae: 218.9502 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 169.5226 - mae: 169.4858 - val_loss: 217.9645 - val_mae: 217.9379 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 147.4492 - mae: 147.4226\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 168.3058 - mae: 168.2843 - val_loss: 216.9433 - val_mae: 216.9303 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 167.4405 - mae: 167.4296 - val_loss: 217.1201 - val_mae: 217.1135 - learning_rate: 5.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 166.6672 - mae: 166.6619 - val_loss: 217.2828 - val_mae: 217.2823 - learning_rate: 5.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 165.9972 - mae: 165.9989 - val_loss: 217.3579 - val_mae: 217.3632 - learning_rate: 5.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 165.3789 - mae: 165.3831 - val_loss: 217.3353 - val_mae: 217.3461 - learning_rate: 5.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 143.7598 - mae: 143.7706\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 164.8046 - mae: 164.8167 - val_loss: 217.2220 - val_mae: 217.2381 - learning_rate: 5.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 164.0795 - mae: 164.0963 - val_loss: 217.2675 - val_mae: 217.2860 - learning_rate: 2.5000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 163.7025 - mae: 163.7219 - val_loss: 217.2043 - val_mae: 217.2253 - learning_rate: 2.5000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 163.3555 - mae: 163.3772 - val_loss: 217.1023 - val_mae: 217.1256 - learning_rate: 2.5000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 162.8813 - mae: 162.9037 - val_loss: 216.9250 - val_mae: 216.9496 - learning_rate: 2.5000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 141.5084 - mae: 141.5305\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 162.5594 - mae: 162.5844 - val_loss: 216.7603 - val_mae: 216.7880 - learning_rate: 2.5000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 162.2175 - mae: 162.2441 - val_loss: 216.6893 - val_mae: 216.7133 - learning_rate: 1.2500e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 162.0916 - mae: 162.1209 - val_loss: 216.6136 - val_mae: 216.6436 - learning_rate: 1.2500e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 161.7157 - mae: 161.7455 - val_loss: 216.5100 - val_mae: 216.5411 - learning_rate: 1.2500e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 161.6011 - mae: 161.6306 - val_loss: 216.3687 - val_mae: 216.4008 - learning_rate: 1.2500e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 140.0805 - mae: 140.1052\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 161.4540 - mae: 161.4846 - val_loss: 216.2478 - val_mae: 216.2808 - learning_rate: 1.2500e-04\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Evalutaing Regularized_DNN_Robust on Test Set...\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001365DFA8720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/stepWARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001365DFA8720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "Training Wide_Network_L2...\n",
      "Epoch 1/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 185.9164 - mae: 185.9292 - val_loss: 202.5921 - val_mae: 202.6411 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 149.5990 - mae: 149.6650 - val_loss: 197.2956 - val_mae: 197.3897 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 153.9388 - mae: 154.0472 - val_loss: 198.5547 - val_mae: 198.6857 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 154.1033 - mae: 154.2466 - val_loss: 197.0490 - val_mae: 197.2121 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 149.6355 - mae: 149.8080 - val_loss: 196.6349 - val_mae: 196.8185 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.1416 - mae: 146.3414 - val_loss: 198.4347 - val_mae: 198.6487 - learning_rate: 0.0010\n",
      "Epoch 7/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 147.3014 - mae: 147.5212 - val_loss: 199.9833 - val_mae: 200.2165 - learning_rate: 0.0010\n",
      "Epoch 8/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 146.9604 - mae: 147.1977 - val_loss: 198.8686 - val_mae: 199.1172 - learning_rate: 0.0010\n",
      "Epoch 9/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 145.3875 - mae: 145.6401 - val_loss: 196.6387 - val_mae: 196.8914 - learning_rate: 0.0010\n",
      "Epoch 10/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 145.1197 - mae: 145.3841 - val_loss: 195.6328 - val_mae: 195.8996 - learning_rate: 0.0010\n",
      "Epoch 11/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 148.5842 - mae: 148.8545 - val_loss: 195.4178 - val_mae: 195.6912 - learning_rate: 0.0010\n",
      "Epoch 12/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 145.8268 - mae: 146.1012 - val_loss: 195.8837 - val_mae: 196.1644 - learning_rate: 0.0010\n",
      "Epoch 13/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 144.6891 - mae: 144.9665 - val_loss: 196.8911 - val_mae: 197.1741 - learning_rate: 0.0010\n",
      "Epoch 14/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 144.6493 - mae: 144.9326 - val_loss: 196.0038 - val_mae: 196.2873 - learning_rate: 0.0010\n",
      "Epoch 15/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 144.7047 - mae: 144.9879 - val_loss: 195.3332 - val_mae: 195.6126 - learning_rate: 0.0010\n",
      "Epoch 16/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 142.7521 - mae: 143.0301 - val_loss: 194.9355 - val_mae: 195.2152 - learning_rate: 0.0010\n",
      "Epoch 17/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 144.7601 - mae: 145.0384 - val_loss: 194.5244 - val_mae: 194.8002 - learning_rate: 0.0010\n",
      "Epoch 18/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 145.6806 - mae: 145.9534 - val_loss: 194.0549 - val_mae: 194.3256 - learning_rate: 0.0010\n",
      "Epoch 19/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 142.0063 - mae: 142.2733 - val_loss: 194.3048 - val_mae: 194.5695 - learning_rate: 0.0010\n",
      "Epoch 20/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 144.4050 - mae: 144.6671 - val_loss: 194.7977 - val_mae: 195.0551 - learning_rate: 0.0010\n",
      "Epoch 21/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 143.5063 - mae: 143.7583 - val_loss: 194.6315 - val_mae: 194.8807 - learning_rate: 0.0010\n",
      "Epoch 22/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 143.0054 - mae: 143.2511 - val_loss: 193.5666 - val_mae: 193.8066 - learning_rate: 0.0010\n",
      "Epoch 23/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 140.1405 - mae: 140.3768 - val_loss: 193.0439 - val_mae: 193.2738 - learning_rate: 0.0010\n",
      "Epoch 24/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 141.9391 - mae: 142.1631 - val_loss: 192.8633 - val_mae: 193.0825 - learning_rate: 0.0010\n",
      "Epoch 25/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 142.6170 - mae: 142.8314 - val_loss: 193.7154 - val_mae: 193.9232 - learning_rate: 0.0010\n",
      "Epoch 26/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 141.8081 - mae: 142.0108 - val_loss: 194.1168 - val_mae: 194.3123 - learning_rate: 0.0010\n",
      "Epoch 27/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 142.2653 - mae: 142.4559 - val_loss: 192.7766 - val_mae: 192.9588 - learning_rate: 0.0010\n",
      "Epoch 28/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 141.1002 - mae: 141.2771 - val_loss: 192.0348 - val_mae: 192.2004 - learning_rate: 0.0010\n",
      "Epoch 29/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 140.6343 - mae: 140.7944 - val_loss: 191.5068 - val_mae: 191.6602 - learning_rate: 0.0010\n",
      "Epoch 30/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 139.3399 - mae: 139.4844 - val_loss: 191.7183 - val_mae: 191.8528 - learning_rate: 0.0010\n",
      "Epoch 31/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 142.4060 - mae: 142.5359 - val_loss: 191.0217 - val_mae: 191.1431 - learning_rate: 0.0010\n",
      "Epoch 32/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 139.1427 - mae: 139.2575 - val_loss: 190.2474 - val_mae: 190.3495 - learning_rate: 0.0010\n",
      "Epoch 33/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 139.7089 - mae: 139.8041 - val_loss: 190.3453 - val_mae: 190.4324 - learning_rate: 0.0010\n",
      "Epoch 34/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 137.4610 - mae: 137.5404 - val_loss: 190.5768 - val_mae: 190.6453 - learning_rate: 0.0010\n",
      "Epoch 35/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 139.0134 - mae: 139.0743 - val_loss: 190.0206 - val_mae: 190.0662 - learning_rate: 0.0010\n",
      "Epoch 36/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 138.9655 - mae: 139.0044 - val_loss: 188.9631 - val_mae: 188.9869 - learning_rate: 0.0010\n",
      "Epoch 37/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 136.4469 - mae: 136.4656 - val_loss: 188.5832 - val_mae: 188.5847 - learning_rate: 0.0010\n",
      "Epoch 38/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 135.5041 - mae: 135.5024 - val_loss: 188.8711 - val_mae: 188.8581 - learning_rate: 0.0010\n",
      "Epoch 39/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 137.9137 - mae: 137.8900 - val_loss: 188.2436 - val_mae: 188.2086 - learning_rate: 0.0010\n",
      "Epoch 40/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 137.2161 - mae: 137.1691 - val_loss: 187.3366 - val_mae: 187.2742 - learning_rate: 0.0010\n",
      "Epoch 41/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 136.5661 - mae: 136.4978 - val_loss: 186.8589 - val_mae: 186.7695 - learning_rate: 0.0010\n",
      "Epoch 42/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 137.5434 - mae: 137.4498 - val_loss: 187.9556 - val_mae: 187.8449 - learning_rate: 0.0010\n",
      "Epoch 43/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 134.7136 - mae: 134.5972 - val_loss: 186.6264 - val_mae: 186.4921 - learning_rate: 0.0010\n",
      "Epoch 44/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 135.8720 - mae: 135.7283 - val_loss: 185.7108 - val_mae: 185.5520 - learning_rate: 0.0010\n",
      "Epoch 45/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 133.2337 - mae: 133.0643 - val_loss: 184.6447 - val_mae: 184.4589 - learning_rate: 0.0010\n",
      "Epoch 46/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 132.9771 - mae: 132.7782 - val_loss: 185.8232 - val_mae: 185.5981 - learning_rate: 0.0010\n",
      "Epoch 47/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 134.2153 - mae: 133.9881 - val_loss: 183.9554 - val_mae: 183.7042 - learning_rate: 0.0010\n",
      "Epoch 48/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 131.5912 - mae: 131.3358 - val_loss: 182.6434 - val_mae: 182.3719 - learning_rate: 0.0010\n",
      "Epoch 49/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 133.0764 - mae: 132.7943 - val_loss: 183.6746 - val_mae: 183.3641 - learning_rate: 0.0010\n",
      "Epoch 50/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 131.8803 - mae: 131.5645 - val_loss: 182.6306 - val_mae: 182.2894 - learning_rate: 0.0010\n",
      "Epoch 51/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 130.1317 - mae: 129.7893 - val_loss: 181.3755 - val_mae: 181.0132 - learning_rate: 0.0010\n",
      "Epoch 52/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 127.9391 - mae: 127.5604 - val_loss: 180.9366 - val_mae: 180.5402 - learning_rate: 0.0010\n",
      "Epoch 53/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 128.0079 - mae: 127.5987 - val_loss: 180.5758 - val_mae: 180.1414 - learning_rate: 0.0010\n",
      "Epoch 54/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 128.9987 - mae: 128.5570 - val_loss: 179.8074 - val_mae: 179.3406 - learning_rate: 0.0010\n",
      "Epoch 55/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 124.9299 - mae: 124.4539 - val_loss: 179.2206 - val_mae: 178.7202 - learning_rate: 0.0010\n",
      "Epoch 56/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 128.4806 - mae: 127.9761 - val_loss: 178.2706 - val_mae: 177.7402 - learning_rate: 0.0010\n",
      "Epoch 57/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 125.7372 - mae: 125.1996 - val_loss: 177.9489 - val_mae: 177.3875 - learning_rate: 0.0010\n",
      "Epoch 58/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 125.1994 - mae: 124.6275 - val_loss: 177.9258 - val_mae: 177.3309 - learning_rate: 0.0010\n",
      "Epoch 59/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 128.5356 - mae: 127.9288 - val_loss: 176.3405 - val_mae: 175.7018 - learning_rate: 0.0010\n",
      "Epoch 60/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 127.5764 - mae: 126.9328 - val_loss: 177.1895 - val_mae: 176.5164 - learning_rate: 0.0010\n",
      "Epoch 61/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 125.5329 - mae: 124.8531 - val_loss: 175.2280 - val_mae: 174.5250 - learning_rate: 0.0010\n",
      "Epoch 62/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 124.5228 - mae: 123.8027 - val_loss: 174.3980 - val_mae: 173.6523 - learning_rate: 0.0010\n",
      "Epoch 63/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 122.6902 - mae: 121.9340 - val_loss: 174.2496 - val_mae: 173.4711 - learning_rate: 0.0010\n",
      "Epoch 64/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 124.0657 - mae: 123.2723 - val_loss: 172.8213 - val_mae: 171.9964 - learning_rate: 0.0010\n",
      "Epoch 65/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 120.8524 - mae: 120.0191 - val_loss: 172.0817 - val_mae: 171.2151 - learning_rate: 0.0010\n",
      "Epoch 66/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 121.8885 - mae: 121.0159 - val_loss: 172.4018 - val_mae: 171.5007 - learning_rate: 0.0010\n",
      "Epoch 67/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 121.1738 - mae: 120.2627 - val_loss: 171.0627 - val_mae: 170.1320 - learning_rate: 0.0010\n",
      "Epoch 68/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 118.6310 - mae: 117.6854 - val_loss: 170.2946 - val_mae: 169.3237 - learning_rate: 0.0010\n",
      "Epoch 69/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 121.0130 - mae: 120.0239 - val_loss: 170.7109 - val_mae: 169.6910 - learning_rate: 0.0010\n",
      "Epoch 70/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 119.3960 - mae: 118.3682 - val_loss: 168.6499 - val_mae: 167.5856 - learning_rate: 0.0010\n",
      "Epoch 71/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 119.8377 - mae: 118.7614 - val_loss: 168.0565 - val_mae: 166.9603 - learning_rate: 0.0010\n",
      "Epoch 72/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 119.1809 - mae: 118.0654 - val_loss: 167.8495 - val_mae: 166.7110 - learning_rate: 0.0010\n",
      "Epoch 73/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 117.7633 - mae: 116.6062 - val_loss: 166.5215 - val_mae: 165.3382 - learning_rate: 0.0010\n",
      "Epoch 74/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 116.2831 - mae: 115.0861 - val_loss: 165.9222 - val_mae: 164.6919 - learning_rate: 0.0010\n",
      "Epoch 75/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 114.0388 - mae: 112.7968 - val_loss: 164.9297 - val_mae: 163.6629 - learning_rate: 0.0010\n",
      "Epoch 76/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 114.4502 - mae: 113.1650 - val_loss: 164.1134 - val_mae: 162.7975 - learning_rate: 0.0010\n",
      "Epoch 77/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 116.8379 - mae: 115.5085 - val_loss: 163.3356 - val_mae: 161.9809 - learning_rate: 0.0010\n",
      "Epoch 78/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 112.5402 - mae: 111.1608 - val_loss: 162.6396 - val_mae: 161.2415 - learning_rate: 0.0010\n",
      "Epoch 79/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 111.6184 - mae: 110.2038 - val_loss: 161.7880 - val_mae: 160.3474 - learning_rate: 0.0010\n",
      "Epoch 80/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 113.8884 - mae: 112.4314 - val_loss: 161.3901 - val_mae: 159.9002 - learning_rate: 0.0010\n",
      "Epoch 81/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 112.5028 - mae: 110.9991 - val_loss: 160.6009 - val_mae: 159.0701 - learning_rate: 0.0010\n",
      "Epoch 82/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 110.7108 - mae: 109.1619 - val_loss: 159.6111 - val_mae: 158.0379 - learning_rate: 0.0010\n",
      "Epoch 83/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 111.1089 - mae: 109.5174 - val_loss: 159.0175 - val_mae: 157.4001 - learning_rate: 0.0010\n",
      "Epoch 84/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 109.4269 - mae: 107.7883 - val_loss: 158.1384 - val_mae: 156.4769 - learning_rate: 0.0010\n",
      "Epoch 85/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 111.8943 - mae: 110.2132 - val_loss: 158.4415 - val_mae: 156.7334 - learning_rate: 0.0010\n",
      "Epoch 86/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 109.7020 - mae: 107.9782 - val_loss: 157.8779 - val_mae: 156.1241 - learning_rate: 0.0010\n",
      "Epoch 87/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 108.0190 - mae: 106.2525 - val_loss: 156.8950 - val_mae: 155.1003 - learning_rate: 0.0010\n",
      "Epoch 88/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 107.2758 - mae: 105.4653 - val_loss: 155.1721 - val_mae: 153.3341 - learning_rate: 0.0010\n",
      "Epoch 89/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 105.9698 - mae: 104.1157 - val_loss: 154.3977 - val_mae: 152.5148 - learning_rate: 0.0010\n",
      "Epoch 90/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 106.4728 - mae: 104.5751 - val_loss: 153.6836 - val_mae: 151.7608 - learning_rate: 0.0010\n",
      "Epoch 91/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 104.4636 - mae: 102.5215 - val_loss: 153.0231 - val_mae: 151.0555 - learning_rate: 0.0010\n",
      "Epoch 92/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 105.8732 - mae: 103.8865 - val_loss: 152.5881 - val_mae: 150.5791 - learning_rate: 0.0010\n",
      "Epoch 93/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 103.9430 - mae: 101.9193 - val_loss: 151.9543 - val_mae: 149.9031 - learning_rate: 0.0010\n",
      "Epoch 94/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 104.5956 - mae: 102.5292 - val_loss: 151.2011 - val_mae: 149.1081 - learning_rate: 0.0010\n",
      "Epoch 95/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 102.9001 - mae: 100.7895 - val_loss: 150.8199 - val_mae: 148.6783 - learning_rate: 0.0010\n",
      "Epoch 96/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 100.8567 - mae: 98.7023 - val_loss: 150.9759 - val_mae: 148.7975 - learning_rate: 0.0010\n",
      "Epoch 97/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 102.3590 - mae: 100.1651 - val_loss: 149.2898 - val_mae: 147.0642 - learning_rate: 0.0010\n",
      "Epoch 98/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 101.7678 - mae: 99.5300 - val_loss: 148.7829 - val_mae: 146.5167 - learning_rate: 0.0010\n",
      "Epoch 99/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 102.0263 - mae: 99.7491 - val_loss: 148.6584 - val_mae: 146.3577 - learning_rate: 0.0010\n",
      "Epoch 100/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 100.0864 - mae: 97.7665 - val_loss: 148.7682 - val_mae: 146.4245 - learning_rate: 0.0010\n",
      "Epoch 101/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 101.5812 - mae: 99.2215 - val_loss: 147.5601 - val_mae: 145.1754 - learning_rate: 0.0010\n",
      "Epoch 102/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 97.2475 - mae: 94.8459 - val_loss: 151.7847 - val_mae: 149.3626 - learning_rate: 0.0010\n",
      "Epoch 103/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 99.6999 - mae: 97.2634 - val_loss: 146.9705 - val_mae: 144.5084 - learning_rate: 0.0010\n",
      "Epoch 104/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 100.1705 - mae: 97.6910 - val_loss: 147.9977 - val_mae: 145.4920 - learning_rate: 0.0010\n",
      "Epoch 105/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 98.4445 - mae: 95.9249 - val_loss: 144.9831 - val_mae: 142.4343 - learning_rate: 0.0010\n",
      "Epoch 106/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 96.4985 - mae: 93.9360 - val_loss: 144.4585 - val_mae: 141.8679 - learning_rate: 0.0010\n",
      "Epoch 107/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 96.0743 - mae: 93.4691 - val_loss: 144.6603 - val_mae: 142.0312 - learning_rate: 0.0010\n",
      "Epoch 108/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 95.9578 - mae: 93.3111 - val_loss: 146.8792 - val_mae: 144.2084 - learning_rate: 0.0010\n",
      "Epoch 109/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 97.7481 - mae: 95.0601 - val_loss: 142.7562 - val_mae: 140.0395 - learning_rate: 0.0010\n",
      "Epoch 110/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 96.1054 - mae: 93.3738 - val_loss: 143.4747 - val_mae: 140.7190 - learning_rate: 0.0010\n",
      "Epoch 111/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 95.8726 - mae: 93.1015 - val_loss: 142.6374 - val_mae: 139.8324 - learning_rate: 0.0010\n",
      "Epoch 112/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 94.8201 - mae: 92.0078 - val_loss: 142.0033 - val_mae: 139.1613 - learning_rate: 0.0010\n",
      "Epoch 113/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 95.1176 - mae: 92.2705 - val_loss: 141.0683 - val_mae: 138.1983 - learning_rate: 0.0010\n",
      "Epoch 114/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 94.0914 - mae: 91.2059 - val_loss: 140.9464 - val_mae: 138.0292 - learning_rate: 0.0010\n",
      "Epoch 115/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 95.5615 - mae: 92.6411 - val_loss: 140.3538 - val_mae: 137.4034 - learning_rate: 0.0010\n",
      "Epoch 116/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 92.1681 - mae: 89.2063 - val_loss: 139.7507 - val_mae: 136.7608 - learning_rate: 0.0010\n",
      "Epoch 117/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 89.9502 - mae: 86.9537 - val_loss: 139.3346 - val_mae: 136.3112 - learning_rate: 0.0010\n",
      "Epoch 118/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 93.7922 - mae: 90.7547 - val_loss: 138.9049 - val_mae: 135.8413 - learning_rate: 0.0010\n",
      "Epoch 119/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 91.2267 - mae: 88.1513 - val_loss: 138.6624 - val_mae: 135.5524 - learning_rate: 0.0010\n",
      "Epoch 120/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 91.5767 - mae: 88.4642 - val_loss: 138.4511 - val_mae: 135.3048 - learning_rate: 0.0010\n",
      "Epoch 121/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 90.4536 - mae: 87.3034 - val_loss: 139.4640 - val_mae: 136.2868 - learning_rate: 0.0010\n",
      "Epoch 122/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 90.8724 - mae: 87.6824 - val_loss: 138.8399 - val_mae: 135.6267 - learning_rate: 0.0010\n",
      "Epoch 123/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 89.9954 - mae: 86.7638 - val_loss: 138.5120 - val_mae: 135.2527 - learning_rate: 0.0010\n",
      "Epoch 124/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 89.4742 - mae: 86.2062 - val_loss: 138.5809 - val_mae: 135.2909 - learning_rate: 0.0010\n",
      "Epoch 125/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 90.3862 - mae: 87.0755 - val_loss: 137.0723 - val_mae: 133.7368 - learning_rate: 0.0010\n",
      "Epoch 126/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 90.6331 - mae: 87.2848 - val_loss: 137.6779 - val_mae: 134.3088 - learning_rate: 0.0010\n",
      "Epoch 127/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 88.2806 - mae: 84.8930 - val_loss: 136.6505 - val_mae: 133.2272 - learning_rate: 0.0010\n",
      "Epoch 128/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 85.8778 - mae: 82.4478 - val_loss: 136.3536 - val_mae: 132.8981 - learning_rate: 0.0010\n",
      "Epoch 129/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 87.0899 - mae: 83.6261 - val_loss: 136.8934 - val_mae: 133.3939 - learning_rate: 0.0010\n",
      "Epoch 130/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 86.4714 - mae: 82.9710 - val_loss: 136.5391 - val_mae: 133.0101 - learning_rate: 0.0010\n",
      "Epoch 131/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 87.6138 - mae: 84.0758 - val_loss: 135.9220 - val_mae: 132.3518 - learning_rate: 0.0010\n",
      "Epoch 132/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 84.2786 - mae: 80.7040 - val_loss: 136.0647 - val_mae: 132.4595 - learning_rate: 0.0010\n",
      "Epoch 133/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 83.6284 - mae: 80.0131 - val_loss: 137.9693 - val_mae: 134.3305 - learning_rate: 0.0010\n",
      "Epoch 134/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 86.2840 - mae: 82.6395 - val_loss: 138.1096 - val_mae: 134.4420 - learning_rate: 0.0010\n",
      "Epoch 135/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 86.0018 - mae: 82.3191 - val_loss: 138.5582 - val_mae: 134.8597 - learning_rate: 0.0010\n",
      "Epoch 136/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 66.1645 - mae: 62.4675\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 85.6887 - mae: 81.9773 - val_loss: 138.1793 - val_mae: 134.4486 - learning_rate: 0.0010\n",
      "Epoch 137/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 85.0503 - mae: 81.3100 - val_loss: 137.0154 - val_mae: 133.2676 - learning_rate: 5.0000e-04\n",
      "Epoch 138/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 83.8224 - mae: 80.0686 - val_loss: 135.0546 - val_mae: 131.2935 - learning_rate: 5.0000e-04\n",
      "Epoch 139/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 83.7767 - mae: 80.0039 - val_loss: 135.4269 - val_mae: 131.6461 - learning_rate: 5.0000e-04\n",
      "Epoch 140/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 83.7955 - mae: 80.0099 - val_loss: 134.7779 - val_mae: 130.9862 - learning_rate: 5.0000e-04\n",
      "Epoch 141/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 82.6397 - mae: 78.8381 - val_loss: 134.8693 - val_mae: 131.0621 - learning_rate: 5.0000e-04\n",
      "Epoch 142/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 82.2155 - mae: 78.3980 - val_loss: 135.2270 - val_mae: 131.4034 - learning_rate: 5.0000e-04\n",
      "Epoch 143/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 83.4720 - mae: 79.6377 - val_loss: 134.9960 - val_mae: 131.1582 - learning_rate: 5.0000e-04\n",
      "Epoch 144/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 83.6098 - mae: 79.7607 - val_loss: 135.3833 - val_mae: 131.5229 - learning_rate: 5.0000e-04\n",
      "Epoch 145/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 63.2776 - mae: 59.4240\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 82.9485 - mae: 79.0813 - val_loss: 134.8364 - val_mae: 130.9667 - learning_rate: 5.0000e-04\n",
      "Epoch 146/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 81.8274 - mae: 77.9531 - val_loss: 134.6386 - val_mae: 130.7622 - learning_rate: 2.5000e-04\n",
      "Epoch 147/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 82.4033 - mae: 78.5200 - val_loss: 136.6929 - val_mae: 132.8055 - learning_rate: 2.5000e-04\n",
      "Epoch 148/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 82.5280 - mae: 78.6380 - val_loss: 134.5871 - val_mae: 130.6948 - learning_rate: 2.5000e-04\n",
      "Epoch 149/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 83.1597 - mae: 79.2601 - val_loss: 135.3444 - val_mae: 131.4294 - learning_rate: 2.5000e-04\n",
      "Epoch 150/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 81.6239 - mae: 77.7180 - val_loss: 134.7709 - val_mae: 130.8635 - learning_rate: 2.5000e-04\n",
      "Epoch 151/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 82.4657 - mae: 78.5543 - val_loss: 135.6287 - val_mae: 131.7070 - learning_rate: 2.5000e-04\n",
      "Epoch 152/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 82.5567 - mae: 78.6350 - val_loss: 134.2356 - val_mae: 130.3111 - learning_rate: 2.5000e-04\n",
      "Epoch 153/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 81.2448 - mae: 77.3125 - val_loss: 134.8129 - val_mae: 130.8783 - learning_rate: 2.5000e-04\n",
      "Epoch 154/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 82.1230 - mae: 78.1866 - val_loss: 134.4406 - val_mae: 130.5023 - learning_rate: 2.5000e-04\n",
      "Epoch 155/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 81.2232 - mae: 77.2777 - val_loss: 134.6994 - val_mae: 130.7429 - learning_rate: 2.5000e-04\n",
      "Epoch 156/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.9165 - mae: 74.9635 - val_loss: 134.2825 - val_mae: 130.3222 - learning_rate: 2.5000e-04\n",
      "Epoch 157/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 81.0071 - mae: 77.0479 - val_loss: 134.1518 - val_mae: 130.1907 - learning_rate: 2.5000e-04\n",
      "Epoch 158/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 80.1090 - mae: 76.1450 - val_loss: 134.3262 - val_mae: 130.3579 - learning_rate: 2.5000e-04\n",
      "Epoch 159/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 80.6185 - mae: 76.6453 - val_loss: 134.0129 - val_mae: 130.0327 - learning_rate: 2.5000e-04\n",
      "Epoch 160/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80.9388 - mae: 76.9569 - val_loss: 134.0445 - val_mae: 130.0602 - learning_rate: 2.5000e-04\n",
      "Epoch 161/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80.1714 - mae: 76.1784 - val_loss: 134.4510 - val_mae: 130.4600 - learning_rate: 2.5000e-04\n",
      "Epoch 162/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80.8367 - mae: 76.8386 - val_loss: 134.9516 - val_mae: 130.9527 - learning_rate: 2.5000e-04\n",
      "Epoch 163/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80.2687 - mae: 76.2621 - val_loss: 134.1827 - val_mae: 130.1745 - learning_rate: 2.5000e-04\n",
      "Epoch 164/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 81.5482 - mae: 77.5374 - val_loss: 133.8899 - val_mae: 129.8746 - learning_rate: 2.5000e-04\n",
      "Epoch 165/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 81.8844 - mae: 77.8640 - val_loss: 134.3371 - val_mae: 130.3148 - learning_rate: 2.5000e-04\n",
      "Epoch 166/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 80.7188 - mae: 76.6899 - val_loss: 134.3065 - val_mae: 130.2772 - learning_rate: 2.5000e-04\n",
      "Epoch 167/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 79.7889 - mae: 75.7547 - val_loss: 133.7667 - val_mae: 129.7299 - learning_rate: 2.5000e-04\n",
      "Epoch 168/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80.7414 - mae: 76.7019 - val_loss: 134.2521 - val_mae: 130.2081 - learning_rate: 2.5000e-04\n",
      "Epoch 169/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 79.1281 - mae: 75.0781 - val_loss: 134.2586 - val_mae: 130.2074 - learning_rate: 2.5000e-04\n",
      "Epoch 170/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 80.9078 - mae: 76.8501 - val_loss: 134.3981 - val_mae: 130.3388 - learning_rate: 2.5000e-04\n",
      "Epoch 171/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.6953 - mae: 75.6290 - val_loss: 133.8601 - val_mae: 129.7885 - learning_rate: 2.5000e-04\n",
      "Epoch 172/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 60.8698 - mae: 56.8025\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 80.8122 - mae: 76.7380 - val_loss: 134.0680 - val_mae: 129.9926 - learning_rate: 2.5000e-04\n",
      "Epoch 173/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 81.3750 - mae: 77.2962 - val_loss: 134.1090 - val_mae: 130.0303 - learning_rate: 1.2500e-04\n",
      "Epoch 174/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 81.1511 - mae: 77.0619 - val_loss: 134.7292 - val_mae: 130.6469 - learning_rate: 1.2500e-04\n",
      "Epoch 175/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.8309 - mae: 74.7460 - val_loss: 134.2000 - val_mae: 130.1067 - learning_rate: 1.2500e-04\n",
      "Epoch 176/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.3423 - mae: 73.2521 - val_loss: 133.6268 - val_mae: 129.5300 - learning_rate: 1.2500e-04\n",
      "Epoch 177/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80.6977 - mae: 76.5985 - val_loss: 133.5798 - val_mae: 129.4859 - learning_rate: 1.2500e-04\n",
      "Epoch 178/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 80.8403 - mae: 76.7435 - val_loss: 133.7833 - val_mae: 129.6858 - learning_rate: 1.2500e-04\n",
      "Epoch 179/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 79.4236 - mae: 75.3225 - val_loss: 134.7771 - val_mae: 130.6760 - learning_rate: 1.2500e-04\n",
      "Epoch 180/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80.3696 - mae: 76.2638 - val_loss: 133.6965 - val_mae: 129.5916 - learning_rate: 1.2500e-04\n",
      "Epoch 181/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.7953 - mae: 75.6857 - val_loss: 133.5466 - val_mae: 129.4355 - learning_rate: 1.2500e-04\n",
      "Epoch 182/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80.7889 - mae: 76.6764 - val_loss: 133.4451 - val_mae: 129.3232 - learning_rate: 1.2500e-04\n",
      "Epoch 183/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.3449 - mae: 74.2262 - val_loss: 133.6548 - val_mae: 129.5395 - learning_rate: 1.2500e-04\n",
      "Epoch 184/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 79.6041 - mae: 75.4827 - val_loss: 134.3886 - val_mae: 130.2701 - learning_rate: 1.2500e-04\n",
      "Epoch 185/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 80.7380 - mae: 76.6102 - val_loss: 133.7787 - val_mae: 129.6568 - learning_rate: 1.2500e-04\n",
      "Epoch 186/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.3493 - mae: 74.2241 - val_loss: 133.4652 - val_mae: 129.3382 - learning_rate: 1.2500e-04\n",
      "Epoch 187/300\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 56.1621 - mae: 52.0364\n",
      "Epoch 187: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.5480 - mae: 74.4174 - val_loss: 133.5766 - val_mae: 129.4424 - learning_rate: 1.2500e-04\n",
      "Epoch 188/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 80.9604 - mae: 76.8265 - val_loss: 134.1067 - val_mae: 129.9747 - learning_rate: 1.0000e-04\n",
      "Epoch 189/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.0276 - mae: 74.8918 - val_loss: 134.2540 - val_mae: 130.1178 - learning_rate: 1.0000e-04\n",
      "Epoch 190/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 80.0345 - mae: 75.8946 - val_loss: 133.8627 - val_mae: 129.7259 - learning_rate: 1.0000e-04\n",
      "Epoch 191/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.6448 - mae: 75.4990 - val_loss: 133.5839 - val_mae: 129.4432 - learning_rate: 1.0000e-04\n",
      "Epoch 192/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.4989 - mae: 75.3557 - val_loss: 133.4576 - val_mae: 129.3071 - learning_rate: 1.0000e-04\n",
      "Epoch 193/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 79.9661 - mae: 75.8195 - val_loss: 133.3989 - val_mae: 129.2540 - learning_rate: 1.0000e-04\n",
      "Epoch 194/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.5737 - mae: 75.4215 - val_loss: 133.6262 - val_mae: 129.4788 - learning_rate: 1.0000e-04\n",
      "Epoch 195/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 79.2458 - mae: 75.0947 - val_loss: 134.1251 - val_mae: 129.9752 - learning_rate: 1.0000e-04\n",
      "Epoch 196/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 77.4471 - mae: 73.2874 - val_loss: 133.8166 - val_mae: 129.6639 - learning_rate: 1.0000e-04\n",
      "Epoch 197/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.3236 - mae: 74.1664 - val_loss: 133.3788 - val_mae: 129.2209 - learning_rate: 1.0000e-04\n",
      "Epoch 198/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.5004 - mae: 73.3398 - val_loss: 133.5743 - val_mae: 129.4129 - learning_rate: 1.0000e-04\n",
      "Epoch 199/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 78.0356 - mae: 73.8691 - val_loss: 133.3699 - val_mae: 129.2074 - learning_rate: 1.0000e-04\n",
      "Epoch 200/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 77.4270 - mae: 73.2613 - val_loss: 133.7459 - val_mae: 129.5828 - learning_rate: 1.0000e-04\n",
      "Epoch 201/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 79.2329 - mae: 75.0669 - val_loss: 133.8925 - val_mae: 129.7249 - learning_rate: 1.0000e-04\n",
      "Epoch 202/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 79.8578 - mae: 75.6836 - val_loss: 133.4052 - val_mae: 129.2366 - learning_rate: 1.0000e-04\n",
      "Epoch 203/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.8202 - mae: 74.6487 - val_loss: 133.2761 - val_mae: 129.1031 - learning_rate: 1.0000e-04\n",
      "Epoch 204/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.1316 - mae: 74.9574 - val_loss: 133.2521 - val_mae: 129.0778 - learning_rate: 1.0000e-04\n",
      "Epoch 205/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 79.3288 - mae: 75.1511 - val_loss: 133.3179 - val_mae: 129.1334 - learning_rate: 1.0000e-04\n",
      "Epoch 206/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.8150 - mae: 73.6369 - val_loss: 133.3404 - val_mae: 129.1605 - learning_rate: 1.0000e-04\n",
      "Epoch 207/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.4321 - mae: 75.2491 - val_loss: 133.5979 - val_mae: 129.4161 - learning_rate: 1.0000e-04\n",
      "Epoch 208/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.0947 - mae: 74.9078 - val_loss: 133.6355 - val_mae: 129.4512 - learning_rate: 1.0000e-04\n",
      "Epoch 209/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 78.6031 - mae: 74.4105 - val_loss: 133.5801 - val_mae: 129.3932 - learning_rate: 1.0000e-04\n",
      "Epoch 210/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.8139 - mae: 75.6254 - val_loss: 133.3623 - val_mae: 129.1728 - learning_rate: 1.0000e-04\n",
      "Epoch 211/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.4559 - mae: 74.2594 - val_loss: 133.3978 - val_mae: 129.2059 - learning_rate: 1.0000e-04\n",
      "Epoch 212/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.8864 - mae: 74.6893 - val_loss: 133.4610 - val_mae: 129.2666 - learning_rate: 1.0000e-04\n",
      "Epoch 213/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 78.5488 - mae: 74.3435 - val_loss: 133.4246 - val_mae: 129.2279 - learning_rate: 1.0000e-04\n",
      "Epoch 214/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.6089 - mae: 74.4059 - val_loss: 133.2254 - val_mae: 129.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 215/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 78.4973 - mae: 74.2896 - val_loss: 133.3226 - val_mae: 129.1208 - learning_rate: 1.0000e-04\n",
      "Epoch 216/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.0075 - mae: 74.8016 - val_loss: 133.5333 - val_mae: 129.3292 - learning_rate: 1.0000e-04\n",
      "Epoch 217/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 78.0433 - mae: 73.8313 - val_loss: 133.4419 - val_mae: 129.2352 - learning_rate: 1.0000e-04\n",
      "Epoch 218/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 76.3960 - mae: 72.1839 - val_loss: 133.5347 - val_mae: 129.3255 - learning_rate: 1.0000e-04\n",
      "Epoch 219/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.6889 - mae: 73.4718 - val_loss: 133.5098 - val_mae: 129.2980 - learning_rate: 1.0000e-04\n",
      "Epoch 220/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 80.1224 - mae: 75.9046 - val_loss: 133.2184 - val_mae: 129.0039 - learning_rate: 1.0000e-04\n",
      "Epoch 221/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.7133 - mae: 75.4942 - val_loss: 133.1999 - val_mae: 128.9826 - learning_rate: 1.0000e-04\n",
      "Epoch 222/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 76.7539 - mae: 72.5295 - val_loss: 133.4494 - val_mae: 129.2297 - learning_rate: 1.0000e-04\n",
      "Epoch 223/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 77.5876 - mae: 73.3591 - val_loss: 133.6474 - val_mae: 129.4216 - learning_rate: 1.0000e-04\n",
      "Epoch 224/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.3477 - mae: 74.1218 - val_loss: 133.3116 - val_mae: 129.0870 - learning_rate: 1.0000e-04\n",
      "Epoch 225/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 78.4974 - mae: 74.2664 - val_loss: 133.1066 - val_mae: 128.8795 - learning_rate: 1.0000e-04\n",
      "Epoch 226/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 78.5848 - mae: 74.3501 - val_loss: 133.0596 - val_mae: 128.8251 - learning_rate: 1.0000e-04\n",
      "Epoch 227/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 77.9759 - mae: 73.7393 - val_loss: 132.9552 - val_mae: 128.7166 - learning_rate: 1.0000e-04\n",
      "Epoch 228/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 78.9104 - mae: 74.6707 - val_loss: 132.9494 - val_mae: 128.7092 - learning_rate: 1.0000e-04\n",
      "Epoch 229/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 78.5368 - mae: 74.2979 - val_loss: 133.0327 - val_mae: 128.7913 - learning_rate: 1.0000e-04\n",
      "Epoch 230/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 78.2905 - mae: 74.0486 - val_loss: 133.3537 - val_mae: 129.1131 - learning_rate: 1.0000e-04\n",
      "Epoch 231/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.4642 - mae: 73.2171 - val_loss: 133.2225 - val_mae: 128.9796 - learning_rate: 1.0000e-04\n",
      "Epoch 232/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 76.9791 - mae: 72.7294 - val_loss: 132.8997 - val_mae: 128.6538 - learning_rate: 1.0000e-04\n",
      "Epoch 233/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.9253 - mae: 73.6708 - val_loss: 132.9010 - val_mae: 128.6528 - learning_rate: 1.0000e-04\n",
      "Epoch 234/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 76.9664 - mae: 72.7104 - val_loss: 133.1859 - val_mae: 128.9353 - learning_rate: 1.0000e-04\n",
      "Epoch 235/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 79.2233 - mae: 74.9670 - val_loss: 133.1615 - val_mae: 128.9085 - learning_rate: 1.0000e-04\n",
      "Epoch 236/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.5355 - mae: 74.2786 - val_loss: 132.8590 - val_mae: 128.6032 - learning_rate: 1.0000e-04\n",
      "Epoch 237/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 78.0955 - mae: 73.8366 - val_loss: 132.9294 - val_mae: 128.6634 - learning_rate: 1.0000e-04\n",
      "Epoch 238/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 76.1285 - mae: 71.8683 - val_loss: 132.9376 - val_mae: 128.6781 - learning_rate: 1.0000e-04\n",
      "Epoch 239/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 76.8089 - mae: 72.5410 - val_loss: 133.1297 - val_mae: 128.8684 - learning_rate: 1.0000e-04\n",
      "Epoch 240/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.8744 - mae: 73.6050 - val_loss: 133.1663 - val_mae: 128.9029 - learning_rate: 1.0000e-04\n",
      "Epoch 241/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 78.0235 - mae: 73.7561 - val_loss: 133.0326 - val_mae: 128.7658 - learning_rate: 1.0000e-04\n",
      "Epoch 242/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.0530 - mae: 73.7828 - val_loss: 132.9493 - val_mae: 128.6789 - learning_rate: 1.0000e-04\n",
      "Epoch 243/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.4214 - mae: 74.1432 - val_loss: 132.9625 - val_mae: 128.6922 - learning_rate: 1.0000e-04\n",
      "Epoch 244/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 79.3487 - mae: 75.0743 - val_loss: 133.2372 - val_mae: 128.9645 - learning_rate: 1.0000e-04\n",
      "Epoch 245/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 77.3594 - mae: 73.0823 - val_loss: 133.2237 - val_mae: 128.9484 - learning_rate: 1.0000e-04\n",
      "Epoch 246/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.2166 - mae: 73.9358 - val_loss: 132.8732 - val_mae: 128.5952 - learning_rate: 1.0000e-04\n",
      "Epoch 247/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.9092 - mae: 73.6280 - val_loss: 132.8412 - val_mae: 128.5608 - learning_rate: 1.0000e-04\n",
      "Epoch 248/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 78.8550 - mae: 74.5703 - val_loss: 133.1621 - val_mae: 128.8791 - learning_rate: 1.0000e-04\n",
      "Epoch 249/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 78.4911 - mae: 74.2022 - val_loss: 133.6873 - val_mae: 129.4022 - learning_rate: 1.0000e-04\n",
      "Epoch 250/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.2348 - mae: 73.9388 - val_loss: 133.4139 - val_mae: 129.1262 - learning_rate: 1.0000e-04\n",
      "Epoch 251/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 77.8919 - mae: 73.6003 - val_loss: 133.0190 - val_mae: 128.7285 - learning_rate: 1.0000e-04\n",
      "Epoch 252/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 79.5045 - mae: 75.2061 - val_loss: 132.7239 - val_mae: 128.4308 - learning_rate: 1.0000e-04\n",
      "Epoch 253/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 76.4829 - mae: 72.1838 - val_loss: 132.7819 - val_mae: 128.4806 - learning_rate: 1.0000e-04\n",
      "Epoch 254/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 76.1084 - mae: 71.8042 - val_loss: 132.9470 - val_mae: 128.6490 - learning_rate: 1.0000e-04\n",
      "Epoch 255/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 77.2419 - mae: 72.9420 - val_loss: 133.0826 - val_mae: 128.7821 - learning_rate: 1.0000e-04\n",
      "Epoch 256/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.1487 - mae: 73.8423 - val_loss: 132.9147 - val_mae: 128.6119 - learning_rate: 1.0000e-04\n",
      "Epoch 257/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 77.3391 - mae: 73.0307 - val_loss: 132.7334 - val_mae: 128.4246 - learning_rate: 1.0000e-04\n",
      "Epoch 258/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.8454 - mae: 73.5318 - val_loss: 132.8511 - val_mae: 128.5435 - learning_rate: 1.0000e-04\n",
      "Epoch 259/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 75.8977 - mae: 71.5808 - val_loss: 133.3648 - val_mae: 129.0551 - learning_rate: 1.0000e-04\n",
      "Epoch 260/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 76.4047 - mae: 72.0919 - val_loss: 133.1483 - val_mae: 128.8355 - learning_rate: 1.0000e-04\n",
      "Epoch 261/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 77.4261 - mae: 73.1060 - val_loss: 132.7138 - val_mae: 128.3993 - learning_rate: 1.0000e-04\n",
      "Epoch 262/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 77.4248 - mae: 73.1063 - val_loss: 132.7166 - val_mae: 128.3998 - learning_rate: 1.0000e-04\n",
      "Epoch 263/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.8053 - mae: 73.4794 - val_loss: 133.0898 - val_mae: 128.7643 - learning_rate: 1.0000e-04\n",
      "Epoch 264/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 77.3423 - mae: 73.0118 - val_loss: 133.5241 - val_mae: 129.2024 - learning_rate: 1.0000e-04\n",
      "Epoch 265/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.8717 - mae: 74.5447 - val_loss: 132.8835 - val_mae: 128.5597 - learning_rate: 1.0000e-04\n",
      "Epoch 266/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.9211 - mae: 73.5900 - val_loss: 132.7465 - val_mae: 128.4116 - learning_rate: 1.0000e-04\n",
      "Epoch 267/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 75.4859 - mae: 71.1503 - val_loss: 132.6448 - val_mae: 128.3164 - learning_rate: 1.0000e-04\n",
      "Epoch 268/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 79.5644 - mae: 75.2297 - val_loss: 132.9444 - val_mae: 128.6138 - learning_rate: 1.0000e-04\n",
      "Epoch 269/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 76.8062 - mae: 72.4684 - val_loss: 133.2718 - val_mae: 128.9391 - learning_rate: 1.0000e-04\n",
      "Epoch 270/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 78.5392 - mae: 74.1994 - val_loss: 133.2758 - val_mae: 128.9365 - learning_rate: 1.0000e-04\n",
      "Epoch 271/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 76.5656 - mae: 72.2238 - val_loss: 132.6356 - val_mae: 128.2953 - learning_rate: 1.0000e-04\n",
      "Epoch 272/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 76.7311 - mae: 72.3858 - val_loss: 132.5568 - val_mae: 128.2065 - learning_rate: 1.0000e-04\n",
      "Epoch 273/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 77.2084 - mae: 72.8630 - val_loss: 132.6091 - val_mae: 128.2666 - learning_rate: 1.0000e-04\n",
      "Epoch 274/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.6878 - mae: 73.3396 - val_loss: 132.6531 - val_mae: 128.3051 - learning_rate: 1.0000e-04\n",
      "Epoch 275/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 75.1438 - mae: 70.7937 - val_loss: 132.7896 - val_mae: 128.4424 - learning_rate: 1.0000e-04\n",
      "Epoch 276/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 76.1695 - mae: 71.8142 - val_loss: 132.9170 - val_mae: 128.5644 - learning_rate: 1.0000e-04\n",
      "Epoch 277/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 75.9644 - mae: 71.6085 - val_loss: 132.8179 - val_mae: 128.4661 - learning_rate: 1.0000e-04\n",
      "Epoch 278/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 77.3249 - mae: 72.9592 - val_loss: 132.5839 - val_mae: 128.2280 - learning_rate: 1.0000e-04\n",
      "Epoch 279/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 75.7022 - mae: 71.3428 - val_loss: 132.9463 - val_mae: 128.5897 - learning_rate: 1.0000e-04\n",
      "Epoch 280/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 76.8020 - mae: 72.4414 - val_loss: 133.2354 - val_mae: 128.8770 - learning_rate: 1.0000e-04\n",
      "Epoch 281/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 75.9925 - mae: 71.6276 - val_loss: 132.5275 - val_mae: 128.1665 - learning_rate: 1.0000e-04\n",
      "Epoch 282/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 76.4985 - mae: 72.1323 - val_loss: 132.5700 - val_mae: 128.1972 - learning_rate: 1.0000e-04\n",
      "Epoch 283/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 77.8170 - mae: 73.4513 - val_loss: 132.4622 - val_mae: 128.0956 - learning_rate: 1.0000e-04\n",
      "Epoch 284/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 76.6393 - mae: 72.2687 - val_loss: 133.0826 - val_mae: 128.7154 - learning_rate: 1.0000e-04\n",
      "Epoch 285/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 76.7683 - mae: 72.3924 - val_loss: 133.5713 - val_mae: 129.2018 - learning_rate: 1.0000e-04\n",
      "Epoch 286/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 75.7292 - mae: 71.3481 - val_loss: 132.6460 - val_mae: 128.2740 - learning_rate: 1.0000e-04\n",
      "Epoch 287/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 74.8367 - mae: 70.4567 - val_loss: 132.4373 - val_mae: 128.0609 - learning_rate: 1.0000e-04\n",
      "Epoch 288/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 76.3162 - mae: 71.9326 - val_loss: 132.3963 - val_mae: 128.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 289/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 76.4144 - mae: 72.0287 - val_loss: 132.5691 - val_mae: 128.1903 - learning_rate: 1.0000e-04\n",
      "Epoch 290/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 75.8071 - mae: 71.4227 - val_loss: 132.9562 - val_mae: 128.5753 - learning_rate: 1.0000e-04\n",
      "Epoch 291/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 74.2900 - mae: 69.9051 - val_loss: 133.1496 - val_mae: 128.7646 - learning_rate: 1.0000e-04\n",
      "Epoch 292/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 77.4801 - mae: 73.0922 - val_loss: 132.4544 - val_mae: 128.0612 - learning_rate: 1.0000e-04\n",
      "Epoch 293/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 77.1088 - mae: 72.7146 - val_loss: 132.3137 - val_mae: 127.9197 - learning_rate: 1.0000e-04\n",
      "Epoch 294/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 77.2593 - mae: 72.8662 - val_loss: 132.4010 - val_mae: 128.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 295/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 77.6283 - mae: 73.2330 - val_loss: 133.3065 - val_mae: 128.9129 - learning_rate: 1.0000e-04\n",
      "Epoch 296/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 76.1255 - mae: 71.7249 - val_loss: 133.4373 - val_mae: 129.0428 - learning_rate: 1.0000e-04\n",
      "Epoch 297/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 76.2671 - mae: 71.8669 - val_loss: 132.5993 - val_mae: 128.2024 - learning_rate: 1.0000e-04\n",
      "Epoch 298/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 76.9015 - mae: 72.4972 - val_loss: 132.2572 - val_mae: 127.8579 - learning_rate: 1.0000e-04\n",
      "Epoch 299/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 76.0743 - mae: 71.6665 - val_loss: 132.2001 - val_mae: 127.7978 - learning_rate: 1.0000e-04\n",
      "Epoch 300/300\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 75.5333 - mae: 71.1271 - val_loss: 132.4513 - val_mae: 128.0470 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 299.\n",
      "Evalutaing Wide_Network_L2 on Test Set...\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "results = {}\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 300\n",
    "PATIENCE = 20\n",
    "\n",
    "# Callbacks for training\n",
    "callbacks = [\n",
    "          EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True, verbose=1),\n",
    "          ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING TENSORFLOW MODEL TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for builder in model_builders:\n",
    "          # Build Model\n",
    "          model = builder(input_dim)\n",
    "          model_name = model.name\n",
    "          print(f\"\\nTraining {model_name}...\")\n",
    "          \n",
    "          # Compile\n",
    "          # RMSprop for the Regularized/Robust model for diversification\n",
    "          optimizer = 'rmsprop' if model_name == 'Regularized_DNN_Robust' else 'adam'\n",
    "          model.compile(optimizer=optimizer, loss=tf.keras.losses.Huber(), metrics=['mae'])\n",
    "          \n",
    "          # Train\n",
    "          history = model.fit(\n",
    "                    X_train, y_train,\n",
    "                    validation_split=0.2, # Use 20% of train data for validation during training\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1\n",
    "          )\n",
    "          \n",
    "          # Evaluate on Test Set\n",
    "          print(f\"Evalutaing {model_name} on Test Set...\")\n",
    "          y_pred = model.predict(X_test).flatten()\n",
    "          \n",
    "          # Calculate Metrics\n",
    "          mae = mean_absolute_error(y_test, y_pred)\n",
    "          mse = mean_squared_error(y_test, y_pred)\n",
    "          r2 = r2_score(y_test, y_pred)\n",
    "          \n",
    "          results[model_name] = {'MAE': mae, 'MSE': mse, 'R2': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8787a737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                       DEEP LEARNING MODEL COMPARISON\n",
      "================================================================================\n",
      "|                        |     MAE |       MSE |     R2 |\n",
      "|:-----------------------|--------:|----------:|-------:|\n",
      "| Wide_Network_L2        | 104.860 | 42713.808 |  0.097 |\n",
      "| Deep_DNN_6_Layers_L2   | 175.244 | 66033.791 | -0.396 |\n",
      "| Simple_DNN_3_Layers_L2 | 179.651 | 69654.026 | -0.473 |\n",
      "| Regularized_DNN_Robust | 210.532 | 90952.389 | -0.923 |\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display Results\n",
    "\n",
    "metrics_df = pd.DataFrame(results).T\n",
    "metrics_df = metrics_df.sort_values(by='R2', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                       DEEP LEARNING MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(metrics_df.to_markdown(floatfmt=\".3f\"))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efc2ef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rayquaza\\AppData\\Local\\Temp\\ipykernel_9720\\3900825063.py:11: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(ax=axes[0], x='Model', y='R2', data=plot_df.sort_values(by='R2', ascending=False), palette='viridis')\n",
      "C:\\Users\\Rayquaza\\AppData\\Local\\Temp\\ipykernel_9720\\3900825063.py:20: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(ax=axes[1], x='Model', y='MAE', data=plot_df.sort_values(by='MAE', ascending=True), palette='plasma')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization\n",
    "\n",
    "# Prepare data for plotting\n",
    "metrics_to_plot = ['R2', 'MAE']\n",
    "plot_df = metrics_df[metrics_to_plot].reset_index().rename(columns={'index': 'Model'})\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "fig.suptitle('TensorFlow Deep Learning Performance Comparison', fontsize=18)\n",
    "\n",
    "# Plot R2 Score\n",
    "sns.barplot(ax=axes[0], x='Model', y='R2', data=plot_df.sort_values(by='R2', ascending=False), palette='viridis')\n",
    "axes[0].set_title('R2 Score (Higher is Better)')\n",
    "axes[0].set_ylim(min(plot_df['R2'].min(), 0) * 1.1, max(plot_df['R2'].max(), 1.0) * 1.05)\n",
    "axes[0].set_ylabel('R2 Score')\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container, fmt='%.3f')\n",
    "\n",
    "# Plot MAE (Mean Absolute Error)\n",
    "sns.barplot(ax=axes[1], x='Model', y='MAE', data=plot_df.sort_values(by='MAE', ascending=True), palette='plasma')\n",
    "axes[1].set_title('Mean Absolute Error (Lower is Better)')\n",
    "axes[1].set_ylabel('Profit ($)')\n",
    "axes[1].tick_params(axis='x', rotation=15)\n",
    "for container in axes[1].containers:\n",
    "    axes[1].bar_label(container, fmt='%.2f')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bca4f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary ---\n",
      "The best performing DL architecture is Wide_Network_L2.\n",
      "R2: 0.09688439673898874, MAE: 104.85967251873016\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Summary ---\")\n",
    "best_model = metrics_df.index[0]\n",
    "best_r2 = metrics_df.iloc[0]['R2']\n",
    "best_mae = metrics_df.iloc[0]['MAE']\n",
    "\n",
    "print(f\"The best performing DL architecture is {best_model}.\")\n",
    "print(f\"R2: {best_r2}, MAE: {best_mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
